{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (1.36.11)\n",
      "Requirement already satisfied: langchain in c:\\users\\zinii\\anaconda3\\lib\\site-packages (0.3.17)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\zinii\\anaconda3\\lib\\site-packages (2.9.10)\n",
      "Requirement already satisfied: pandas in c:\\users\\zinii\\appdata\\roaming\\python\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\zinii\\anaconda3\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: botocore<1.37.0,>=1.36.11 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from boto3) (1.36.11)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from boto3) (0.11.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (0.3.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (0.3.4)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\zinii\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\zinii\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\zinii\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from botocore<1.37.0,>=1.36.11->boto3) (1.26.16)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\zinii\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zinii\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain) (2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install boto3 langchain psycopg2-binary pandas faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I test if I can create a session and if it works: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session(region_name='us-west-2')\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# Option 1: Use default credential provider chain\n",
    "session = boto3.Session()\n",
    "\n",
    "print(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All available LLM models in my region: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID: amazon.titan-tg1-large\n",
      "Model ID: amazon.titan-embed-g1-text-02\n",
      "Model ID: amazon.titan-text-lite-v1:0:4k\n",
      "Model ID: amazon.titan-text-lite-v1\n",
      "Model ID: amazon.titan-text-express-v1:0:8k\n",
      "Model ID: amazon.titan-text-express-v1\n",
      "Model ID: amazon.nova-pro-v1:0\n",
      "Model ID: amazon.nova-lite-v1:0\n",
      "Model ID: amazon.nova-micro-v1:0\n",
      "Model ID: amazon.titan-embed-text-v1:2:8k\n",
      "Model ID: amazon.titan-embed-text-v1\n",
      "Model ID: amazon.titan-embed-text-v2:0\n",
      "Model ID: amazon.titan-embed-image-v1:0\n",
      "Model ID: amazon.titan-embed-image-v1\n",
      "Model ID: amazon.titan-image-generator-v1:0\n",
      "Model ID: amazon.titan-image-generator-v1\n",
      "Model ID: amazon.titan-image-generator-v2:0\n",
      "Model ID: amazon.rerank-v1:0\n",
      "Model ID: stability.stable-diffusion-xl-v1:0\n",
      "Model ID: stability.stable-diffusion-xl-v1\n",
      "Model ID: stability.sd3-large-v1:0\n",
      "Model ID: stability.sd3-5-large-v1:0\n",
      "Model ID: stability.stable-image-core-v1:0\n",
      "Model ID: stability.stable-image-core-v1:1\n",
      "Model ID: stability.stable-image-ultra-v1:0\n",
      "Model ID: stability.stable-image-ultra-v1:1\n",
      "Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0:18k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0:51k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0:200k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0\n",
      "Model ID: anthropic.claude-3-5-haiku-20241022-v1:0\n",
      "Model ID: anthropic.claude-instant-v1:2:100k\n",
      "Model ID: anthropic.claude-instant-v1\n",
      "Model ID: anthropic.claude-v2:0:18k\n",
      "Model ID: anthropic.claude-v2:0:100k\n",
      "Model ID: anthropic.claude-v2:1:18k\n",
      "Model ID: anthropic.claude-v2:1:200k\n",
      "Model ID: anthropic.claude-v2:1\n",
      "Model ID: anthropic.claude-v2\n",
      "Model ID: anthropic.claude-3-sonnet-20240229-v1:0:28k\n",
      "Model ID: anthropic.claude-3-sonnet-20240229-v1:0:200k\n",
      "Model ID: anthropic.claude-3-sonnet-20240229-v1:0\n",
      "Model ID: anthropic.claude-3-haiku-20240307-v1:0:48k\n",
      "Model ID: anthropic.claude-3-haiku-20240307-v1:0:200k\n",
      "Model ID: anthropic.claude-3-haiku-20240307-v1:0\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0:12k\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0:28k\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0:200k\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0\n",
      "Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0:18k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0:51k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0:200k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0\n",
      "Model ID: cohere.command-text-v14:7:4k\n",
      "Model ID: cohere.command-text-v14\n",
      "Model ID: cohere.command-r-v1:0\n",
      "Model ID: cohere.command-r-plus-v1:0\n",
      "Model ID: cohere.command-light-text-v14:7:4k\n",
      "Model ID: cohere.command-light-text-v14\n",
      "Model ID: cohere.embed-english-v3:0:512\n",
      "Model ID: cohere.embed-english-v3\n",
      "Model ID: cohere.embed-multilingual-v3:0:512\n",
      "Model ID: cohere.embed-multilingual-v3\n",
      "Model ID: cohere.rerank-v3-5:0\n",
      "Model ID: meta.llama3-8b-instruct-v1:0\n",
      "Model ID: meta.llama3-70b-instruct-v1:0\n",
      "Model ID: meta.llama3-1-8b-instruct-v1:0:128k\n",
      "Model ID: meta.llama3-1-8b-instruct-v1:0\n",
      "Model ID: meta.llama3-1-70b-instruct-v1:0:128k\n",
      "Model ID: meta.llama3-1-70b-instruct-v1:0\n",
      "Model ID: meta.llama3-1-405b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-11b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-90b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-1b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-3b-instruct-v1:0\n",
      "Model ID: meta.llama3-3-70b-instruct-v1:0\n",
      "Model ID: mistral.mistral-7b-instruct-v0:2\n",
      "Model ID: mistral.mixtral-8x7b-instruct-v0:1\n",
      "Model ID: mistral.mistral-large-2402-v1:0\n",
      "Model ID: mistral.mistral-large-2407-v1:0\n",
      "Model ID: luma.ray-v2:0\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "bedrock = boto3.client('bedrock', region_name='us-west-2')  # change to your region\n",
    "models = bedrock.list_foundation_models()\n",
    "\n",
    "for model in models['modelSummaries']:\n",
    "    print(f\"Model ID: {model['modelId']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connection to Amazon Redshift:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connexion r√©ussie !\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialisation du client Redshift Data\n",
    "client = boto3.client('redshift-data', region_name='us-west-2')\n",
    "\n",
    "# Param√®tres de connexion\n",
    "database = 'dev'  # Remplace par le nom de ta base de donn√©es\n",
    "workgroup_name = 'wz-solutions-redshift-workgroup'  # Remplace par ton workgroup\n",
    "\n",
    "# Requ√™te simple pour tester la connexion\n",
    "sql_query = 'SELECT 1;'\n",
    "\n",
    "try:\n",
    "    response = client.execute_statement(\n",
    "        Database=database,\n",
    "        WorkgroupName=workgroup_name,  # Ne sp√©cifie plus db_user ici\n",
    "        Sql=sql_query\n",
    "    )\n",
    "    print(\"Connexion r√©ussie !\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur de connexion : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test de faire une requete SQL √† Amazon Redshift et voir si on peut avoir le r√©sultat de la requete: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requ√™te envoy√©e, ID : 979c0d74-e9e9-427c-97ce-50786006a8a5\n",
      "En attente des r√©sultats...\n",
      "\n",
      "R√©sultats de la requ√™te :\n",
      "['GN_1180180102051605', 'GN|1180180102051605|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180102342604', 'GN|1180180102342604|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180102501103', 'GN|1180180102501103|22910|1|00000', '2022-10-10', 'NULL', '2022-03-27', '2022-09-02', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180102596604', 'GN|1180180102596604|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180102978210', 'GN|1180180102978210|22910|1|00000', '2022-10-10', 'NULL', '2022-03-27', '2022-09-02', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180103044102', 'GN|1180180103044102|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180103080601', 'GN|1180180103080601|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180103081401', 'GN|1180180103081401|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180103156901', 'GN|1180180103156901|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180103398201', 'GN|1180180103398201|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "# Initialisation du client Redshift Data\n",
    "client = boto3.client('redshift-data', region_name='us-west-2')\n",
    "\n",
    "# Param√®tres de connexion\n",
    "database = 'dev'  # Remplace par le nom de ta base de donn√©es\n",
    "workgroup_name = 'wz-solutions-redshift-workgroup'  # Remplace par ton workgroup\n",
    "\n",
    "# Requ√™te SQL √† ex√©cuter\n",
    "sql_query = 'SELECT * FROM consoma LIMIT 10;'  # Remplace par ta table\n",
    "\n",
    "try:\n",
    "    # Ex√©cuter la requ√™te SQL\n",
    "    response = client.execute_statement(\n",
    "        Database=database,\n",
    "        WorkgroupName=workgroup_name,  # Ne sp√©cifie plus db_user ici\n",
    "        Sql=sql_query\n",
    "    )\n",
    "    \n",
    "    # R√©cup√©rer l'ID de l'ex√©cution de la requ√™te\n",
    "    statement_id = response['Id']\n",
    "    print(f\"Requ√™te envoy√©e, ID : {statement_id}\")\n",
    "\n",
    "    # Attendre que la requ√™te soit termin√©e\n",
    "    while True:\n",
    "        status_response = client.describe_statement(Id=statement_id)\n",
    "        status = status_response['Status']\n",
    "\n",
    "        if status in ['FINISHED', 'FAILED', 'ABORTED']:\n",
    "            break\n",
    "        print(\"En attente des r√©sultats...\")\n",
    "        time.sleep(2)  # Pause avant la prochaine v√©rification\n",
    "\n",
    "    # V√©rifier si la requ√™te s'est bien ex√©cut√©e\n",
    "    if status == 'FINISHED':\n",
    "        # R√©cup√©rer les r√©sultats\n",
    "        result_response = client.get_statement_result(Id=statement_id)\n",
    "        records = result_response.get('Records', [])\n",
    "\n",
    "        # Afficher les r√©sultats\n",
    "        if records:\n",
    "            print(\"\\nR√©sultats de la requ√™te :\")\n",
    "            for row in records:\n",
    "                print([col.get('stringValue', 'NULL') for col in row])  # Adaptation pour afficher chaque ligne\n",
    "        else:\n",
    "            print(\"Aucun r√©sultat trouv√©.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Erreur lors de l'ex√©cution : {status_response.get('Error', 'Erreur inconnue')}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erreur de connexion ou d'ex√©cution : {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt 1: Analyse des tables et colonnes de notre base de donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Analyse des Tables Redshift üìä\n",
      "\n",
      "\n",
      "    Table: abonnements\n",
      "    1. Le r√¥le de cette table est de stocker les informations relatives aux abonnements des clients.\n",
      "    2. cle_abonnement (identifiant unique de l'abonnement), date_entree_local_abonnement (date d'entr√©e de l'abonnement), date_resiliation_abonnement (date de r√©siliation de l'abonnement), date_souscription_abonnement (date de souscription de l'abonnement).\n",
      "    \n",
      "    Table: consommations\n",
      "    1. Le r√¥le de cette table est de stocker les informations relatives aux consommations d'eau des clients.\n",
      "    2. annee_conso (ann√©e de la consommation), mois_conso (mois de la consommation), diametre_nominal (diam√®tre nominal de la canalisation), volume_mois (volume d'eau consomm√© pendant le mois), type_abaque (type d'abaque utilis√© pour le calcul de la consommation), libelle_categorie_abonne (libell√© de la cat√©gorie de l'abonn√©), code_contrat (code du contrat), libelle_territoire (libell√© du territoire), libelle_region (libell√© de la r√©gion), cle_pds (identifiant unique du point de livraison), date_conso_mois (date de la consommation mensuelle).\n",
      "    \n",
      "    Table: factures\n",
      "    1. Le r√¥le de cette table est de stocker les informations relatives aux factures √©mises aux clients.\n",
      "    2. num_fac_par_pds (num√©ro de facture par point de livraison), nb_jours_connus (nombre de jours connus pour la facturation), nb_factures_par_pds (nombre de factures par point de livraison), conso_facture (consommation factur√©e), cle_facture (identifiant unique de la facture), cle_abonnement (identifiant de l'abonnement associ√© √† la facture), date_emission_facture (date d'√©mission de la facture), date_releve_index_facture (date du relev√© d'index de la facture), date_releve_index_precedent_facture_composite (date du relev√© d'index pr√©c√©dent composite).\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "\n",
    "# ---- AWS CONFIGURATION ----\n",
    "AWS_REGION = \"us-west-2\"\n",
    "MODEL_ID = \"mistral.mixtral-8x7b-instruct-v0:1\"  # Utilisation de Mistral AI\n",
    "\n",
    "# ---- REDSHIFT SERVERLESS CONFIGURATION ----\n",
    "DATABASE = \"dev\"  # Remplace par ta base de donn√©es\n",
    "WORKGROUP_NAME = \"wz-solutions-redshift-workgroup\"  # Remplace par ton workgroup\n",
    "\n",
    "# ---- INITIALISATION DES CLIENTS ----\n",
    "bedrock = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\n",
    "redshift_client = boto3.client(\"redshift-data\", region_name=AWS_REGION)\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR R√âCUP√âRER LES TABLES REDSHIFT ----\n",
    "def get_redshift_tables():\n",
    "    \"\"\"R√©cup√®re la liste des tables disponibles dans la base de donn√©es Redshift.\"\"\"\n",
    "    sql_query = \"SELECT tablename FROM pg_catalog.pg_tables WHERE schemaname = 'public';\"\n",
    "    try:\n",
    "        response = redshift_client.execute_statement(\n",
    "            Database=DATABASE,\n",
    "            WorkgroupName=WORKGROUP_NAME,\n",
    "            Sql=sql_query\n",
    "        )\n",
    "\n",
    "        statement_id = response['Id']\n",
    "        while True:\n",
    "            status_response = redshift_client.describe_statement(Id=statement_id)\n",
    "            status = status_response[\"Status\"]\n",
    "            if status in [\"FINISHED\", \"FAILED\", \"ABORTED\"]:\n",
    "                break\n",
    "            time.sleep(2)\n",
    "\n",
    "        if status == \"FINISHED\":\n",
    "            result_response = redshift_client.get_statement_result(Id=statement_id)\n",
    "            tables = [row[0].get('stringValue', 'NULL') for row in result_response.get(\"Records\", [])]\n",
    "            return tables if tables else \"Aucune table trouv√©e.\"\n",
    "        else:\n",
    "            return f\"Erreur lors de l'ex√©cution : {status_response.get('Error', 'Erreur inconnue')}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Erreur de connexion ou d'ex√©cution : {str(e)}\"\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR R√âCUP√âRER LES COLONNES D'UNE TABLE ----\n",
    "def get_table_columns(table_name):\n",
    "    \"\"\"R√©cup√®re les colonnes et leur description d'une table Redshift.\"\"\"\n",
    "    sql_query = f\"\"\"\n",
    "        SELECT column_name, data_type\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_name = '{table_name}';\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = redshift_client.execute_statement(\n",
    "            Database=DATABASE,\n",
    "            WorkgroupName=WORKGROUP_NAME,\n",
    "            Sql=sql_query\n",
    "        )\n",
    "\n",
    "        statement_id = response['Id']\n",
    "        while True:\n",
    "            status_response = redshift_client.describe_statement(Id=statement_id)\n",
    "            status = status_response[\"Status\"]\n",
    "            if status in [\"FINISHED\", \"FAILED\", \"ABORTED\"]:\n",
    "                break\n",
    "            time.sleep(2)\n",
    "\n",
    "        if status == \"FINISHED\":\n",
    "            result_response = redshift_client.get_statement_result(Id=statement_id)\n",
    "            columns = [\n",
    "                f\"{row[0].get('stringValue', 'NULL')} ({row[1].get('stringValue', 'NULL')})\"\n",
    "                for row in result_response.get(\"Records\", [])\n",
    "            ]\n",
    "            return columns if columns else \"Aucune colonne trouv√©e.\"\n",
    "        else:\n",
    "            return f\"Erreur lors de l'ex√©cution : {status_response.get('Error', 'Erreur inconnue')}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Erreur de connexion ou d'ex√©cution : {str(e)}\"\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR ANALYSER LES TABLES AVEC L'AGENT ----\n",
    "def agent_analyze_tables():\n",
    "    \"\"\"Analyse et d√©crit chaque table d√©tect√©e dans Redshift.\"\"\"\n",
    "    tables = get_redshift_tables()\n",
    "    if isinstance(tables, str):\n",
    "        return tables\n",
    "\n",
    "    all_tables_info = []\n",
    "    for table in tables:\n",
    "        columns = get_table_columns(table)\n",
    "        all_tables_info.append(f\"Table: {table}\\nColonnes: {', '.join(columns)}\")\n",
    "\n",
    "    # Construire le prompt pour Mistral AI\n",
    "    prompt = f\"\"\"\n",
    "    Tu es un expert en bases de donn√©es. Analyse et d√©cris chacune des tables trouv√©es dans Amazon Redshift.\n",
    "    \n",
    "    Voici les informations trouv√©es :\n",
    "    {chr(10).join(all_tables_info)}\n",
    "\n",
    "    Pour chaque table :\n",
    "    1. Donne son r√¥le dans la base de donn√©es.\n",
    "    2. Explique √† quoi sert chaque colonne.\n",
    "    \n",
    "    R√©ponds de mani√®re simple et concise, chaque description de colonne doit √™tre de la m√™me longueur et la plus courte et compl√®te possible.\n",
    "    \"\"\"\n",
    "\n",
    "    return analyze_with_mistral(prompt)\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR INTERAGIR AVEC MISTRAL AI ----\n",
    "def analyze_with_mistral(prompt):\n",
    "    \"\"\"Envoie un prompt √† Mistral AI via Amazon Bedrock.\"\"\"\n",
    "    request_body = {\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 800,\n",
    "        \"temperature\": 0.3,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=MODEL_ID,\n",
    "        body=json.dumps(request_body)\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response[\"body\"].read())\n",
    "    return response_body.get(\"outputs\", [{}])[0].get(\"text\", \"\")\n",
    "\n",
    "\n",
    "# ---- EX√âCUTION ----\n",
    "if __name__ == \"__main__\":\n",
    "    response = agent_analyze_tables()\n",
    "    print(\"\\nüìä Analyse des Tables Redshift üìä\\n\")\n",
    "    print(response) \n",
    "    rep_prompt1 = response \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Envoi de la requ√™te √† Redshift: SELECT * FROM factures LIMIT 50;\n",
      "‚úÖ Requ√™te envoy√©e, ID: bfd6d9be-76fe-409f-bacd-f87c4f8839c9\n",
      "‚è≥ En attente des r√©sultats...\n",
      "‚úÖ Requ√™te termin√©e, r√©cup√©ration des r√©sultats...\n",
      "üîÑ Envoi du prompt √† Mistral AI...\n",
      "‚úÖ R√©ponse re√ßue de Mistral.\n",
      "\n",
      "üîé **Rapport d'Anomalies** üîé\n",
      "\n",
      "\n",
      "    Anomalie 1 :\n",
      "    - **Type d'anomalie** : Valeurs nulles\n",
      "    - **Description** : Les champs \"nb_jours_connus\", \"nb_factures_par_pds\", \"date_releve_index_facture\", \"date_releve_index_precedent_facture_composite\" contiennent des valeurs nulles.\n",
      "    - **Requ√™te SQL** :\n",
      "    ```\n",
      "    SELECT * FROM factures\n",
      "    WHERE nb_jours_connus IS NULL\n",
      "    OR nb_factures_par_pds IS NULL\n",
      "    OR date_releve_index_facture IS NULL\n",
      "    OR date_releve_index_precedent_facture_composite IS NULL;\n",
      "    ```\n",
      "\n",
      "    Anomalie 2 :\n",
      "    - **Type d'anomalie** : Doublons\n",
      "    - **Description** : Les champs \"num_fac_par_pds\" et \"cle_abonnement\" contiennent des doublons.\n",
      "    - **Requ√™te SQL** :\n",
      "    ```\n",
      "    SELECT num_fac_par_pds, cle_abonnement, COUNT(*) as nb_occurences\n",
      "    FROM factures\n",
      "    GROUP BY num_fac_par_pds, cle_abonnement\n",
      "    HAVING nb_occurences > 1;\n",
      "    ```\n",
      "\n",
      "    Anomalie 3 :\n",
      "    - **Type d'anomalie** : Erreurs de format\n",
      "    - **Description** : Le champ \"date_emission_facture\" contient des valeurs au format incorrect.\n",
      "    - **Requ√™te SQL** :\n",
      "    ```\n",
      "    SELECT * FROM factures\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "# ---- AWS CONFIGURATION ----\n",
    "AWS_REGION = \"us-west-2\"\n",
    "MODEL_ID = \"mistral.mixtral-8x7b-instruct-v0:1\"  # Utilisation de Mistral AI\n",
    "\n",
    "# ---- REDSHIFT SERVERLESS CONFIGURATION ----\n",
    "DATABASE = \"dev\"  \n",
    "WORKGROUP_NAME = \"wz-solutions-redshift-workgroup\"  \n",
    "\n",
    "# ---- INITIALISATION DES CLIENTS ----\n",
    "bedrock = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\n",
    "redshift_client = boto3.client(\"redshift-data\", region_name=AWS_REGION)\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR R√âCUP√âRER UN √âCHANTILLON D'UNE TABLE ----\n",
    "def get_table_sample(table_name):\n",
    "    \"\"\"R√©cup√®re 1000 lignes d'une table Redshift pour analyse.\"\"\"\n",
    "    sql_query = f\"SELECT * FROM {table_name} LIMIT 50;\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"üîÑ Envoi de la requ√™te √† Redshift: {sql_query}\")\n",
    "        response = redshift_client.execute_statement(\n",
    "            Database=DATABASE,\n",
    "            WorkgroupName=WORKGROUP_NAME,\n",
    "            Sql=sql_query\n",
    "        )\n",
    "\n",
    "        statement_id = response['Id']\n",
    "        print(f\"‚úÖ Requ√™te envoy√©e, ID: {statement_id}\")\n",
    "\n",
    "        # Timeout apr√®s 60 secondes\n",
    "        start_time = time.time()\n",
    "        while True:\n",
    "            status_response = redshift_client.describe_statement(Id=statement_id)\n",
    "            status = status_response[\"Status\"]\n",
    "\n",
    "            if status in [\"FINISHED\", \"FAILED\", \"ABORTED\"]:\n",
    "                break\n",
    "            \n",
    "            # V√©rification du timeout (60 secondes max)\n",
    "            if time.time() - start_time > 60:\n",
    "                print(\"‚è≥ Timeout d√©pass√© (60s). Annulation de la requ√™te.\")\n",
    "                return \"Timeout: La requ√™te a pris trop de temps.\"\n",
    "\n",
    "            print(\"‚è≥ En attente des r√©sultats...\")\n",
    "            time.sleep(3)  # V√©rification toutes les 3 secondes\n",
    "\n",
    "        if status == \"FINISHED\":\n",
    "            print(\"‚úÖ Requ√™te termin√©e, r√©cup√©ration des r√©sultats...\")\n",
    "            result_response = redshift_client.get_statement_result(Id=statement_id)\n",
    "            records = [\n",
    "                \", \".join([col.get('stringValue', 'NULL') for col in row])\n",
    "                for row in result_response.get(\"Records\", [])\n",
    "            ]\n",
    "            return records if records else \"Aucune donn√©e trouv√©e.\"\n",
    "        else:\n",
    "            print(f\"‚ùå Erreur d'ex√©cution: {status}\")\n",
    "            return f\"Erreur lors de l'ex√©cution: {status_response.get('Error', 'Erreur inconnue')}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur de connexion ou d'ex√©cution : {str(e)}\")\n",
    "        return f\"Erreur : {str(e)}\"\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR D√âTECTER LES ANOMALIES ----\n",
    "def agent_detect_anomalies(table_name):\n",
    "    \"\"\"D√©tecte les anomalies d'une table sp√©cifique dans Redshift via Mistral AI.\"\"\"\n",
    "    table_sample = get_table_sample(table_name)\n",
    "    \n",
    "    if isinstance(table_sample, str):\n",
    "        return table_sample  # Si erreur, on la renvoie directement\n",
    "\n",
    "    formatted_sample = \"\\n\".join(table_sample)\n",
    "\n",
    "    # Construction du prompt\n",
    "    prompt = f\"\"\"\n",
    "    Tu es un expert en qualit√© des donn√©es.\n",
    "    {rep_prompt1}\n",
    "    \n",
    "    Voici un √©chantillon de la table \"{table_name}\":\n",
    "    {formatted_sample}\n",
    "    \n",
    "    Identifie les anomalies (valeurs nulles, doublons, erreurs de format, etc.).\n",
    "    G√©n√®re une requ√™te SQL pour afficher les lignes contenant des donn√©es incorrectes.\n",
    "\n",
    "    R√©ponds en suivant ce format :\n",
    "    - **Type d'anomalie** : [Cat√©gorie de l'anomalie]\n",
    "    - **Description** : [Br√®ve explication]\n",
    "    - **Requ√™te SQL** : [Requ√™te pour afficher les donn√©es erron√©es]\n",
    "    \"\"\"\n",
    "\n",
    "    return analyze_with_mistral(prompt)\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR INTERAGIR AVEC MISTRAL AI ----\n",
    "def analyze_with_mistral(prompt):\n",
    "    \"\"\"Envoie un prompt √† Mistral AI via Amazon Bedrock.\"\"\"\n",
    "    request_body = {\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 400,\n",
    "        \"temperature\": 0.3,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        print(\"üîÑ Envoi du prompt √† Mistral AI...\")\n",
    "        response = bedrock.invoke_model(\n",
    "            modelId=MODEL_ID,\n",
    "            body=json.dumps(request_body)\n",
    "        )\n",
    "        print(\"‚úÖ R√©ponse re√ßue de Mistral.\")\n",
    "\n",
    "        response_body = json.loads(response[\"body\"].read())\n",
    "        return response_body.get(\"outputs\", [{}])[0].get(\"text\", \"\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur d'interaction avec Mistral AI : {str(e)}\")\n",
    "        return f\"Erreur : {str(e)}\"\n",
    "\n",
    "\n",
    "# ---- EX√âCUTION ----\n",
    "if __name__ == \"__main__\":\n",
    "    table_name = input(\"üîç Entrez le nom de la table √† analyser : \")\n",
    "    response = agent_detect_anomalies(table_name)\n",
    "\n",
    "    print(\"\\nüîé **Rapport d'Anomalies** üîé\\n\")\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
