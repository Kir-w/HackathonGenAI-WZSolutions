{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for boto3 from https://files.pythonhosted.org/packages/4e/a5/e6f90b0a768560a0c44cb9076a313ee6d669ec98fd2747a8451832403ffe/boto3-1.36.11-py3-none-any.whl.metadata\n",
      "  Downloading boto3-1.36.11-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/e9/65/e5cc2876078fa5f1a621c8429f0174855c7e9831060d350626dbf8d2a10c/langchain-0.3.17-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.3.17-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting psycopg2-binary\n",
      "  Obtaining dependency information for psycopg2-binary from https://files.pythonhosted.org/packages/61/69/3b3d7bd583c6d3cbe5100802efa5beacaacc86e37b653fc708bf3d6853b8/psycopg2_binary-2.9.10-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading psycopg2_binary-2.9.10-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\zinii\\appdata\\roaming\\python\\python311\\site-packages (2.2.3)\n",
      "Collecting faiss-cpu\n",
      "  Obtaining dependency information for faiss-cpu from https://files.pythonhosted.org/packages/2c/2d/d2a4171a9cca9a7c04cd9d6f9441a37f1e0558724b90bf7fc7db08553601/faiss_cpu-1.10.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading faiss_cpu-1.10.0-cp311-cp311-win_amd64.whl.metadata (4.5 kB)\n",
      "Collecting botocore<1.37.0,>=1.36.11 (from boto3)\n",
      "  Obtaining dependency information for botocore<1.37.0,>=1.36.11 from https://files.pythonhosted.org/packages/2c/ce/e97be00389d51a010c0680ea688a073737ca3b2de6f924800fc61bf68e41/botocore-1.36.11-py3-none-any.whl.metadata\n",
      "  Downloading botocore-1.36.11-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from boto3) (0.10.0)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3)\n",
      "  Obtaining dependency information for s3transfer<0.12.0,>=0.11.0 from https://files.pythonhosted.org/packages/1b/ac/e7dc469e49048dc57f62e0c555d2ee3117fa30813d2a1a2962cce3a2a82a/s3transfer-0.11.2-py3-none-any.whl.metadata\n",
      "  Downloading s3transfer-0.11.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Collecting langchain-core<0.4.0,>=0.3.33 (from langchain)\n",
      "  Obtaining dependency information for langchain-core<0.4.0,>=0.3.33 from https://files.pythonhosted.org/packages/98/78/463bc92174555cc04b3e234faa169bb8b58f36fff77892d7b8ae2b4f58e4/langchain_core-0.3.33-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.3.33-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Obtaining dependency information for langchain-text-splitters<0.4.0,>=0.3.3 from https://files.pythonhosted.org/packages/4b/83/f8081c3bea416bd9d9f0c26af795c74f42c24f9ad3c4fbf361b7d69de134/langchain_text_splitters-0.3.5-py3-none-any.whl.metadata\n",
      "  Downloading langchain_text_splitters-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.4,>=0.1.17 from https://files.pythonhosted.org/packages/47/3b/02313e378f6328ada43ee43ecc81a398b4f68e207c94770d1ed6aac6cca2/langsmith-0.3.4-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.3.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Obtaining dependency information for pydantic<3.0.0,>=2.7.4 from https://files.pythonhosted.org/packages/f4/3c/8cc1cc84deffa6e25d2d0c688ebb80635dfdbf1dbea3e30c541c8cf4d860/pydantic-2.10.6-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\zinii\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\zinii\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\zinii\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2025.1)\n",
      "Collecting numpy<2,>=1.22.4 (from langchain)\n",
      "  Obtaining dependency information for numpy<2,>=1.22.4 from https://files.pythonhosted.org/packages/3f/6b/5610004206cf7f8e7ad91c5a85a8c71b2f2f8051a0c0c4d5916b76d6cbb2/numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.0/61.0 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from faiss-cpu) (23.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from botocore<1.37.0,>=1.36.11->boto3) (1.26.16)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.33->langchain)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging (from faiss-cpu)\n",
      "  Obtaining dependency information for packaging from https://files.pythonhosted.org/packages/88/ef/eb23f262cca3c0c4eb7ab1933c3b1f03d021f2c48f54763065b6f0e321be/packaging-24.2-py3-none-any.whl.metadata\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\zinii\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (4.12.2)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/2a/39/e50c7c3a983047577ee07d2a9e53faf5a69493943ec3f6a384bdc792deb2/httpx-0.28.1-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Obtaining dependency information for orjson<4.0.0,>=3.9.14 from https://files.pythonhosted.org/packages/00/f8/bb60a4644287a544ec81df1699d5b965776bc9848d9029d9f9b3402ac8bb/orjson-3.10.15-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading orjson-3.10.15-cp311-cp311-win_amd64.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.9/42.9 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Obtaining dependency information for zstandard<0.24.0,>=0.23.0 from https://files.pythonhosted.org/packages/be/a2/4272175d47c623ff78196f3c10e9dc7045c1b9caf3735bf041e65271eca4/zstandard-0.23.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading zstandard-0.23.0-cp311-cp311-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Obtaining dependency information for annotated-types>=0.6.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Obtaining dependency information for pydantic-core==2.27.2 from https://files.pythonhosted.org/packages/e8/ef/013f07248041b74abd48a385e2110aa3a9bbfef0fbd97d4e6d07d2f5b89a/pydantic_core-2.27.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zinii\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.5.0)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/87/f5/72347bc88306acb359581ac4d52f23c0ef445b57157adedb9aee0cd689d2/httpcore-1.0.7-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Obtaining dependency information for h11<0.15,>=0.13 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain) (2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.0)\n",
      "Using cached boto3-1.36.11-py3-none-any.whl (139 kB)\n",
      "Using cached langchain-0.3.17-py3-none-any.whl (1.0 MB)\n",
      "Using cached psycopg2_binary-2.9.10-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "Using cached faiss_cpu-1.10.0-cp311-cp311-win_amd64.whl (13.7 MB)\n",
      "Using cached botocore-1.36.11-py3-none-any.whl (13.3 MB)\n",
      "Using cached langchain_core-0.3.33-py3-none-any.whl (412 kB)\n",
      "Using cached langchain_text_splitters-0.3.5-py3-none-any.whl (31 kB)\n",
      "Using cached langsmith-0.3.4-py3-none-any.whl (333 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "Using cached s3transfer-0.11.2-py3-none-any.whl (84 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached orjson-3.10.15-cp311-cp311-win_amd64.whl (133 kB)\n",
      "Using cached zstandard-0.23.0-cp311-cp311-win_amd64.whl (495 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: zstandard, pydantic-core, psycopg2-binary, packaging, orjson, numpy, jsonpatch, h11, annotated-types, pydantic, httpcore, faiss-cpu, botocore, s3transfer, httpx, langsmith, boto3, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: zstandard\n",
      "    Found existing installation: zstandard 0.19.0\n",
      "    Uninstalling zstandard-0.19.0:\n",
      "      Successfully uninstalled zstandard-0.19.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.8\n",
      "    Uninstalling pydantic-1.10.8:\n",
      "      Successfully uninstalled pydantic-1.10.8\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.76\n",
      "    Uninstalling botocore-1.29.76:\n",
      "      Successfully uninstalled botocore-1.29.76\n",
      "Successfully installed annotated-types-0.7.0 boto3-1.36.11 botocore-1.36.11 faiss-cpu-1.10.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jsonpatch-1.33 langchain-0.3.17 langchain-core-0.3.33 langchain-text-splitters-0.3.5 langsmith-0.3.4 numpy-1.26.4 orjson-3.10.15 packaging-24.2 psycopg2-binary-2.9.10 pydantic-2.10.6 pydantic-core-2.27.2 s3transfer-0.11.2 zstandard-0.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "aiobotocore 2.5.0 requires botocore<1.29.77,>=1.29.76, but you have botocore 1.36.11 which is incompatible.\n",
      "anaconda-cloud-auth 0.1.3 requires pydantic<2.0, but you have pydantic 2.10.6 which is incompatible.\n",
      "numba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\n",
      "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2024.12.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install boto3 langchain psycopg2-binary pandas faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session(region_name='us-west-2')\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# Option 1: Use default credential provider chain\n",
    "session = boto3.Session()\n",
    "\n",
    "print(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2: Use specific profile\n",
    "session = boto3.Session(profile_name='default')\n",
    "\n",
    "# Option 3: Use environment variables\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'your_access_key'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'your_secret_key'\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'your-region-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All available models in my region: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID: amazon.titan-tg1-large\n",
      "Model ID: amazon.titan-embed-g1-text-02\n",
      "Model ID: amazon.titan-text-lite-v1:0:4k\n",
      "Model ID: amazon.titan-text-lite-v1\n",
      "Model ID: amazon.titan-text-express-v1:0:8k\n",
      "Model ID: amazon.titan-text-express-v1\n",
      "Model ID: amazon.nova-pro-v1:0\n",
      "Model ID: amazon.nova-lite-v1:0\n",
      "Model ID: amazon.nova-micro-v1:0\n",
      "Model ID: amazon.titan-embed-text-v1:2:8k\n",
      "Model ID: amazon.titan-embed-text-v1\n",
      "Model ID: amazon.titan-embed-text-v2:0\n",
      "Model ID: amazon.titan-embed-image-v1:0\n",
      "Model ID: amazon.titan-embed-image-v1\n",
      "Model ID: amazon.titan-image-generator-v1:0\n",
      "Model ID: amazon.titan-image-generator-v1\n",
      "Model ID: amazon.titan-image-generator-v2:0\n",
      "Model ID: amazon.rerank-v1:0\n",
      "Model ID: stability.stable-diffusion-xl-v1:0\n",
      "Model ID: stability.stable-diffusion-xl-v1\n",
      "Model ID: stability.sd3-large-v1:0\n",
      "Model ID: stability.sd3-5-large-v1:0\n",
      "Model ID: stability.stable-image-core-v1:0\n",
      "Model ID: stability.stable-image-core-v1:1\n",
      "Model ID: stability.stable-image-ultra-v1:0\n",
      "Model ID: stability.stable-image-ultra-v1:1\n",
      "Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0:18k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0:51k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0:200k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0\n",
      "Model ID: anthropic.claude-3-5-haiku-20241022-v1:0\n",
      "Model ID: anthropic.claude-instant-v1:2:100k\n",
      "Model ID: anthropic.claude-instant-v1\n",
      "Model ID: anthropic.claude-v2:0:18k\n",
      "Model ID: anthropic.claude-v2:0:100k\n",
      "Model ID: anthropic.claude-v2:1:18k\n",
      "Model ID: anthropic.claude-v2:1:200k\n",
      "Model ID: anthropic.claude-v2:1\n",
      "Model ID: anthropic.claude-v2\n",
      "Model ID: anthropic.claude-3-sonnet-20240229-v1:0:28k\n",
      "Model ID: anthropic.claude-3-sonnet-20240229-v1:0:200k\n",
      "Model ID: anthropic.claude-3-sonnet-20240229-v1:0\n",
      "Model ID: anthropic.claude-3-haiku-20240307-v1:0:48k\n",
      "Model ID: anthropic.claude-3-haiku-20240307-v1:0:200k\n",
      "Model ID: anthropic.claude-3-haiku-20240307-v1:0\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0:12k\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0:28k\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0:200k\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0\n",
      "Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0:18k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0:51k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0:200k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0\n",
      "Model ID: cohere.command-text-v14:7:4k\n",
      "Model ID: cohere.command-text-v14\n",
      "Model ID: cohere.command-r-v1:0\n",
      "Model ID: cohere.command-r-plus-v1:0\n",
      "Model ID: cohere.command-light-text-v14:7:4k\n",
      "Model ID: cohere.command-light-text-v14\n",
      "Model ID: cohere.embed-english-v3:0:512\n",
      "Model ID: cohere.embed-english-v3\n",
      "Model ID: cohere.embed-multilingual-v3:0:512\n",
      "Model ID: cohere.embed-multilingual-v3\n",
      "Model ID: cohere.rerank-v3-5:0\n",
      "Model ID: meta.llama3-8b-instruct-v1:0\n",
      "Model ID: meta.llama3-70b-instruct-v1:0\n",
      "Model ID: meta.llama3-1-8b-instruct-v1:0:128k\n",
      "Model ID: meta.llama3-1-8b-instruct-v1:0\n",
      "Model ID: meta.llama3-1-70b-instruct-v1:0:128k\n",
      "Model ID: meta.llama3-1-70b-instruct-v1:0\n",
      "Model ID: meta.llama3-1-405b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-11b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-90b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-1b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-3b-instruct-v1:0\n",
      "Model ID: meta.llama3-3-70b-instruct-v1:0\n",
      "Model ID: mistral.mistral-7b-instruct-v0:2\n",
      "Model ID: mistral.mixtral-8x7b-instruct-v0:1\n",
      "Model ID: mistral.mistral-large-2402-v1:0\n",
      "Model ID: mistral.mistral-large-2407-v1:0\n",
      "Model ID: luma.ray-v2:0\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "bedrock = boto3.client('bedrock', region_name='us-west-2')  # change to your region\n",
    "models = bedrock.list_foundation_models()\n",
    "\n",
    "for model in models['modelSummaries']:\n",
    "    print(f\"Model ID: {model['modelId']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: What are three interesting facts about the Pacific Northwest?\n",
      "\n",
      "Titan's response: \n",
      "Here are three interesting facts about the Pacific Northwest: \n",
      "\n",
      "1. \"The Pacific Northwest is one of the most beautiful places in the United States. Located along the coast of the Pacific Ocean, it includes Washington, Oregon, and Idaho. The region is known for its stunning scenery, including mountains, forests, and waterways. Here are three interesting facts about the Pacific Northwest:\n",
      "2. The Cascade Range is one of the most prominent mountain ranges in the Pacific Northwest. It includes several volcanoes, including Mount St. Helens and Mount Rainier, and offers some of the best skiing and hiking in the United States.\n",
      "3. The region is also home to several indigenous tribes, including the Nez Perce, Flathead, and Salish. These tribes have a rich history and culture and continue to play an important role in the Pacific Northwest today.\" \n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "def simple_titan_agent(prompt: str) -> str:\n",
    "    # Initialize Bedrock Runtime client in us-west-2\n",
    "    bedrock = boto3.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        region_name='us-west-2'\n",
    "    )\n",
    "    \n",
    "    # Prepare the request for Titan\n",
    "    request_body = {\n",
    "        \"inputText\": prompt,\n",
    "        \"textGenerationConfig\": {\n",
    "            \"maxTokenCount\": 100,\n",
    "            \"temperature\": 0,\n",
    "            \"topP\": 1,\n",
    "            \"stopSequences\": []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Use Titan Express model\n",
    "    model_id = 'amazon.titan-text-express-v1'\n",
    "    \n",
    "    # Invoke the model\n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body=json.dumps(request_body)\n",
    "    )\n",
    "    \n",
    "    # Parse and return the response\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    return response_body.get('results', [{}])[0].get('outputText', '')\n",
    "\n",
    "# Test the agent\n",
    "if __name__ == \"__main__\":\n",
    "    test_prompt = \"What are three interesting facts about the Pacific Northwest?\"\n",
    "    \n",
    "    try:\n",
    "        response = simple_titan_agent(test_prompt)\n",
    "        print(\"\\nPrompt:\", test_prompt)\n",
    "        print(\"\\nTitan's response:\", response)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreatedAt': datetime.datetime(2025, 2, 1, 21, 38, 14, 565000, tzinfo=tzlocal()), 'Database': 'dev', 'DbUser': 'IAM:child-account-21-user-1', 'Id': '970d035b-afe0-49ce-af60-d965dad6b91a', 'WorkgroupName': 'wz-solutions-redshift-workgroup', 'ResponseMetadata': {'RequestId': '970d035b-afe0-49ce-af60-d965dad6b91a', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '970d035b-afe0-49ce-af60-d965dad6b91a', 'content-type': 'application/x-amz-json-1.1', 'content-length': '180', 'date': 'Sat, 01 Feb 2025 20:38:14 GMT'}, 'RetryAttempts': 0}}\n",
      "Connexion r√©ussie !\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialisation du client Redshift Data\n",
    "client = boto3.client('redshift-data', region_name='us-west-2')\n",
    "\n",
    "# Param√®tres de connexion\n",
    "database = 'dev'  # Remplace par le nom de ta base de donn√©es\n",
    "workgroup_name = 'wz-solutions-redshift-workgroup'  # Remplace par ton workgroup\n",
    "\n",
    "# Requ√™te simple pour tester la connexion\n",
    "sql_query = 'SELECT 1;'\n",
    "\n",
    "try:\n",
    "    response = client.execute_statement(\n",
    "        Database=database,\n",
    "        WorkgroupName=workgroup_name,  # Ne sp√©cifie plus db_user ici\n",
    "        Sql=sql_query\n",
    "    )\n",
    "    print(\"Connexion r√©ussie !\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur de connexion : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requ√™te envoy√©e, ID : 979c0d74-e9e9-427c-97ce-50786006a8a5\n",
      "En attente des r√©sultats...\n",
      "\n",
      "R√©sultats de la requ√™te :\n",
      "['GN_1180180102051605', 'GN|1180180102051605|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180102342604', 'GN|1180180102342604|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180102501103', 'GN|1180180102501103|22910|1|00000', '2022-10-10', 'NULL', '2022-03-27', '2022-09-02', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180102596604', 'GN|1180180102596604|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180102978210', 'GN|1180180102978210|22910|1|00000', '2022-10-10', 'NULL', '2022-03-27', '2022-09-02', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180103044102', 'GN|1180180103044102|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180103080601', 'GN|1180180103080601|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180103081401', 'GN|1180180103081401|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180103156901', 'GN|1180180103156901|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180103398201', 'GN|1180180103398201|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "# Initialisation du client Redshift Data\n",
    "client = boto3.client('redshift-data', region_name='us-west-2')\n",
    "\n",
    "# Param√®tres de connexion\n",
    "database = 'dev'  # Remplace par le nom de ta base de donn√©es\n",
    "workgroup_name = 'wz-solutions-redshift-workgroup'  # Remplace par ton workgroup\n",
    "\n",
    "# Requ√™te SQL √† ex√©cuter\n",
    "sql_query = 'SELECT * FROM consoma LIMIT 10;'  # Remplace par ta table\n",
    "\n",
    "try:\n",
    "    # Ex√©cuter la requ√™te SQL\n",
    "    response = client.execute_statement(\n",
    "        Database=database,\n",
    "        WorkgroupName=workgroup_name,  # Ne sp√©cifie plus db_user ici\n",
    "        Sql=sql_query\n",
    "    )\n",
    "    \n",
    "    # R√©cup√©rer l'ID de l'ex√©cution de la requ√™te\n",
    "    statement_id = response['Id']\n",
    "    print(f\"Requ√™te envoy√©e, ID : {statement_id}\")\n",
    "\n",
    "    # Attendre que la requ√™te soit termin√©e\n",
    "    while True:\n",
    "        status_response = client.describe_statement(Id=statement_id)\n",
    "        status = status_response['Status']\n",
    "\n",
    "        if status in ['FINISHED', 'FAILED', 'ABORTED']:\n",
    "            break\n",
    "        print(\"En attente des r√©sultats...\")\n",
    "        time.sleep(2)  # Pause avant la prochaine v√©rification\n",
    "\n",
    "    # V√©rifier si la requ√™te s'est bien ex√©cut√©e\n",
    "    if status == 'FINISHED':\n",
    "        # R√©cup√©rer les r√©sultats\n",
    "        result_response = client.get_statement_result(Id=statement_id)\n",
    "        records = result_response.get('Records', [])\n",
    "\n",
    "        # Afficher les r√©sultats\n",
    "        if records:\n",
    "            print(\"\\nR√©sultats de la requ√™te :\")\n",
    "            for row in records:\n",
    "                print([col.get('stringValue', 'NULL') for col in row])  # Adaptation pour afficher chaque ligne\n",
    "        else:\n",
    "            print(\"Aucun r√©sultat trouv√©.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Erreur lors de l'ex√©cution : {status_response.get('Error', 'Erreur inconnue')}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erreur de connexion ou d'ex√©cution : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requ√™te envoy√©e, ID : 7267a7c4-ae12-4479-9a26-6323221fe820\n",
      "En attente des r√©sultats...\n",
      "\n",
      "üìä Rapport de Qualit√© des Donn√©es üìä\n",
      "\n",
      "\n",
      "Anomalies d√©tect√©es :\n",
      "- Des dates de d√©but de contrat manquantes.\n",
      "- Des dates de fin de contrat manquantes.\n",
      "- Des dates de d√©but de contrat ant√©rieures √† la date de fin de contrat.\n",
      "\n",
      "Requ√™te SQL de validation :\n",
      "SELECT *\n",
      "FROM abonnements\n",
      "WHERE date_de_fin_contrat < date_de_debut_contrat;\n",
      "\n",
      "Recommandations d'am√©lioration :\n",
      "- V√©rifier et corriger les dates de d√©but et de fin de contrat manquantes.\n",
      "- V√©rifier la coh√©rence des dates de d√©but et de fin de contrat.\n",
      "- Enrichir la table avec des informations compl√©mentaires sur les contrats.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "\n",
    "# ---- AWS CONFIGURATION ----\n",
    "AWS_REGION = \"us-west-2\"\n",
    "MODEL_ID = \"amazon.titan-text-express-v1\"\n",
    "\n",
    "# ---- REDSHIFT SERVERLESS CONFIGURATION ----\n",
    "DATABASE = \"dev\"  # Remplace par ta base de donn√©es\n",
    "WORKGROUP_NAME = \"wz-solutions-redshift-workgroup\"  # Remplace par ton workgroup\n",
    "\n",
    "# ---- INITIALISATION DES CLIENTS ----\n",
    "bedrock = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\n",
    "redshift_client = boto3.client(\"redshift-data\", region_name=AWS_REGION)\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR INTERROGER REDSHIFT ----\n",
    "def query_redshift(sql_query):\n",
    "    \"\"\"Ex√©cute une requ√™te SQL sur Redshift Serverless et retourne les r√©sultats.\"\"\"\n",
    "    try:\n",
    "        response = redshift_client.execute_statement(\n",
    "            Database=DATABASE,\n",
    "            WorkgroupName=WORKGROUP_NAME,\n",
    "            Sql=sql_query\n",
    "        )\n",
    "\n",
    "        statement_id = response['Id']\n",
    "        print(f\"Requ√™te envoy√©e, ID : {statement_id}\")\n",
    "\n",
    "        while True:\n",
    "            status_response = redshift_client.describe_statement(Id=statement_id)\n",
    "            status = status_response[\"Status\"]\n",
    "\n",
    "            if status in [\"FINISHED\", \"FAILED\", \"ABORTED\"]:\n",
    "                break\n",
    "            print(\"En attente des r√©sultats...\")\n",
    "            time.sleep(2)\n",
    "\n",
    "        if status == \"FINISHED\":\n",
    "            result_response = redshift_client.get_statement_result(Id=statement_id)\n",
    "            records = result_response.get(\"Records\", [])\n",
    "            return records if records else \"Aucun r√©sultat trouv√©.\"\n",
    "        else:\n",
    "            return f\"Erreur lors de l'ex√©cution : {status_response.get('Error', 'Erreur inconnue')}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Erreur de connexion ou d'ex√©cution : {str(e)}\"\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR ANALYSER LES DONN√âES AVEC AMAZON TITAN ----\n",
    "def analyze_data_with_titan(prompt):\n",
    "    \"\"\"Envoie un prompt structur√© √† Amazon Titan pour d√©tecter les anomalies et proposer des actions correctives.\"\"\"\n",
    "    request_body = {\n",
    "        \"inputText\": prompt,\n",
    "        \"textGenerationConfig\": {\n",
    "            \"maxTokenCount\": 300,\n",
    "            \"temperature\": 0,\n",
    "            \"topP\": 1,\n",
    "            \"stopSequences\": []\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=MODEL_ID,\n",
    "        body=json.dumps(request_body)\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response[\"body\"].read())\n",
    "    return response_body.get(\"results\", [{}])[0].get(\"outputText\", \"\")\n",
    "\n",
    "\n",
    "# ---- FONCTION PRINCIPALE : ANALYSE DE QUALIT√â DES DONN√âES ----\n",
    "def data_quality_analysis(table_name):\n",
    "    \"\"\"Analyse la qualit√© des donn√©es d'une table Redshift et d√©tecte des anomalies.\"\"\"\n",
    "    sql_query = f\"SELECT * FROM {table_name} LIMIT 10;\"\n",
    "    records = query_redshift(sql_query)\n",
    "\n",
    "    if isinstance(records, str):\n",
    "        return records\n",
    "\n",
    "    formatted_data = \"\\n\".join([\", \".join([col.get('stringValue', 'NULL') for col in row]) for row in records])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Tu es un expert en qualit√© des donn√©es, sp√©cialis√© dans l'analyse de tables Redshift.\n",
    "    \n",
    "    Voici un √©chantillon de la table \"{table_name}\":\n",
    "    {formatted_data}\n",
    "    \n",
    "    1. Identifie les anomalies ou incoh√©rences dans ces donn√©es.\n",
    "    2. G√©n√®re une requ√™te SQL pour approfondir l'analyse.\n",
    "    3. Sugg√®re des bonnes pratiques pour am√©liorer la qualit√© des donn√©es.\n",
    "\n",
    "    Format attendu :\n",
    "    - Anomalies d√©tect√©es\n",
    "    - Requ√™te SQL de validation\n",
    "    - Recommandations d'am√©lioration\n",
    "    \"\"\"\n",
    "\n",
    "    return analyze_data_with_titan(prompt)\n",
    "\n",
    "\n",
    "# ---- EX√âCUTION ----\n",
    "if __name__ == \"__main__\":\n",
    "    table_name = \"abonnements\"  # Remplace par le nom de ta table Redshift\n",
    "    response = data_quality_analysis(table_name)\n",
    "\n",
    "    print(\"\\nüìä Rapport de Qualit√© des Donn√©es üìä\\n\")\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROSPER: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Analyse des Tables Redshift üìä\n",
      "\n",
      "\n",
      "    Table: abonnements\n",
      "\n",
      "    1. Le r√¥le de cette table dans la base de donn√©es est de stocker les informations relatives aux abonnements des clients. Cela inclut des d√©tails tels que le num√©ro d'abonnement, les dates d'entr√©e, de r√©siliation et de souscription.\n",
      "\n",
      "    2. Les colonnes de cette table sont :\n",
      "\n",
      "    - cle_abonnement (character varying) : Cette colonne stocke le num√©ro d'abonnement unique pour chaque client.\n",
      "    \n",
      "    - date_entree_local_abonnement (date) : Cette colonne enregistre la date √† laquelle l'abonnement a √©t√© souscrit par le client.\n",
      "    \n",
      "    - date_resiliation_abonnement (date) : Cette colonne stocke la date √† laquelle l'abonnement a √©t√© r√©sili√© par le client. Si l'abonnement est toujours actif, cette valeur sera NULL.\n",
      "    \n",
      "    - date_souscription_abonnement (date) : Cette colonne enregistre la date √† laquelle l'abonnement a √©t√© souscrit par le client. Cette valeur devrait √™tre identique √† celle stock√©e dans la colonne date_entree_local_abonnement.\n",
      "\n",
      "    Table: consommations\n",
      "\n",
      "    1. Le r√¥le de cette table dans la base de donn√©es est de stocker les informations sur la consommation d'eau pour chaque client. Cela inclut des d√©tails tels que le volume consomm√©, le diam√®tre nominal de la conduite, le type d'abaque utilis√© pour le calcul de la consommation, ainsi que des informations sur la cat√©gorie de l'abonn√©, le contrat, le territoire et la r√©gion.\n",
      "\n",
      "    2. Les colonnes de cette table sont :\n",
      "\n",
      "    - annee_conso (integer) : Cette colonne stocke l'ann√©e de consommation.\n",
      "    \n",
      "    - mois_conso (integer) : Cette colonne enregistre le mois de consommation.\n",
      "    \n",
      "    - diametre_nominal (real) : Cette colonne stocke le diam√®tre nominal de la conduite d'eau pour le client.\n",
      "    \n",
      "    - volume_mois (double precision) : Cette colonne enregistre le volume d'eau consomm√© par le client pendant le mois sp√©cifi√©.\n",
      "    \n",
      "    - type_abaque (character varying) : Cette colonne stocke le type d'abaque utilis√© pour calculer la consommation d'eau pour le client.\n",
      "    \n",
      "    - libelle_categorie_abonne (character varying) : Cette colonne enregistre la cat√©gorie de l'abonn√© (par exemple, r√©sidentiel, commercial, industriel).\n",
      "    \n",
      "    - code_contrat (character varying) : Cette colonne stocke le code de contrat associ√© √† l'abonnement du client.\n",
      "    \n",
      "    - libelle_territoire (character varying) : Cette colonne enregistre le nom du territoire o√π se trouve l'abonnement du client.\n",
      "    \n",
      "    - libelle_region (character varying) : Cette colonne stocke le nom de la r√©gion o√π se trouve l'abonnement du client.\n",
      "    \n",
      "    - cle_pds (character varying) : Cette colonne stocke un identifiant unique pour chaque point de livraison (PDL).\n",
      "    \n",
      "    - date_conso_mois (date) : Cette colonne enregistre la date √† laquelle la consommation a √©t√© mesur√©e.\n",
      "\n",
      "    Table: factures\n",
      "\n",
      "    1. Le r√¥le de cette table dans la base de donn√©es est de stocker les informations sur les factures √©mises pour chaque abonnement. Cela inclut des d√©tails tels que le num√©ro de facture, le nombre de jours factur√©s, le nombre de factures par point de livraison, la consommation factur√©e et les dates d'√©mission, de relev√© d'index et de relev√© d'index pr√©c√©dent.\n",
      "\n",
      "    2. Les colonnes de cette table sont :\n",
      "\n",
      "    - num_fac_par_pds (integer) : Cette colonne stocke le num√©ro de facture par point de livraison.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "\n",
    "# ---- AWS CONFIGURATION ----\n",
    "AWS_REGION = \"us-west-2\"\n",
    "MODEL_ID = \"mistral.mixtral-8x7b-instruct-v0:1\"  # Utilisation de Mistral AI\n",
    "\n",
    "# ---- REDSHIFT SERVERLESS CONFIGURATION ----\n",
    "DATABASE = \"dev\"  # Remplace par ta base de donn√©es\n",
    "WORKGROUP_NAME = \"wz-solutions-redshift-workgroup\"  # Remplace par ton workgroup\n",
    "\n",
    "# ---- INITIALISATION DES CLIENTS ----\n",
    "bedrock = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\n",
    "redshift_client = boto3.client(\"redshift-data\", region_name=AWS_REGION)\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR R√âCUP√âRER LES TABLES REDSHIFT ----\n",
    "def get_redshift_tables():\n",
    "    \"\"\"R√©cup√®re la liste des tables disponibles dans la base de donn√©es Redshift.\"\"\"\n",
    "    sql_query = \"SELECT tablename FROM pg_catalog.pg_tables WHERE schemaname = 'public';\"\n",
    "    try:\n",
    "        response = redshift_client.execute_statement(\n",
    "            Database=DATABASE,\n",
    "            WorkgroupName=WORKGROUP_NAME,\n",
    "            Sql=sql_query\n",
    "        )\n",
    "\n",
    "        statement_id = response['Id']\n",
    "        while True:\n",
    "            status_response = redshift_client.describe_statement(Id=statement_id)\n",
    "            status = status_response[\"Status\"]\n",
    "            if status in [\"FINISHED\", \"FAILED\", \"ABORTED\"]:\n",
    "                break\n",
    "            time.sleep(2)\n",
    "\n",
    "        if status == \"FINISHED\":\n",
    "            result_response = redshift_client.get_statement_result(Id=statement_id)\n",
    "            tables = [row[0].get('stringValue', 'NULL') for row in result_response.get(\"Records\", [])]\n",
    "            return tables if tables else \"Aucune table trouv√©e.\"\n",
    "        else:\n",
    "            return f\"Erreur lors de l'ex√©cution : {status_response.get('Error', 'Erreur inconnue')}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Erreur de connexion ou d'ex√©cution : {str(e)}\"\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR R√âCUP√âRER LES COLONNES D'UNE TABLE ----\n",
    "def get_table_columns(table_name):\n",
    "    \"\"\"R√©cup√®re les colonnes et leur description d'une table Redshift.\"\"\"\n",
    "    sql_query = f\"\"\"\n",
    "        SELECT column_name, data_type\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_name = '{table_name}';\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = redshift_client.execute_statement(\n",
    "            Database=DATABASE,\n",
    "            WorkgroupName=WORKGROUP_NAME,\n",
    "            Sql=sql_query\n",
    "        )\n",
    "\n",
    "        statement_id = response['Id']\n",
    "        while True:\n",
    "            status_response = redshift_client.describe_statement(Id=statement_id)\n",
    "            status = status_response[\"Status\"]\n",
    "            if status in [\"FINISHED\", \"FAILED\", \"ABORTED\"]:\n",
    "                break\n",
    "            time.sleep(2)\n",
    "\n",
    "        if status == \"FINISHED\":\n",
    "            result_response = redshift_client.get_statement_result(Id=statement_id)\n",
    "            columns = [\n",
    "                f\"{row[0].get('stringValue', 'NULL')} ({row[1].get('stringValue', 'NULL')})\"\n",
    "                for row in result_response.get(\"Records\", [])\n",
    "            ]\n",
    "            return columns if columns else \"Aucune colonne trouv√©e.\"\n",
    "        else:\n",
    "            return f\"Erreur lors de l'ex√©cution : {status_response.get('Error', 'Erreur inconnue')}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Erreur de connexion ou d'ex√©cution : {str(e)}\"\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR ANALYSER LES TABLES AVEC L'AGENT ----\n",
    "def agent_analyze_tables():\n",
    "    \"\"\"Analyse et d√©crit chaque table d√©tect√©e dans Redshift.\"\"\"\n",
    "    tables = get_redshift_tables()\n",
    "    if isinstance(tables, str):\n",
    "        return tables\n",
    "\n",
    "    all_tables_info = []\n",
    "    for table in tables:\n",
    "        columns = get_table_columns(table)\n",
    "        all_tables_info.append(f\"Table: {table}\\nColonnes: {', '.join(columns)}\")\n",
    "\n",
    "    # Construire le prompt pour Mistral AI\n",
    "    prompt = f\"\"\"\n",
    "    Tu es un expert en bases de donn√©es. Analyse et d√©cris chacune des tables trouv√©es dans Amazon Redshift.\n",
    "    \n",
    "    Voici les informations trouv√©es :\n",
    "    {chr(10).join(all_tables_info)}\n",
    "\n",
    "    Pour chaque table :\n",
    "    1. Donne son r√¥le dans la base de donn√©es.\n",
    "    2. Explique √† quoi sert chaque colonne.\n",
    "    \n",
    "    R√©ponds de mani√®re d√©taill√©e et p√©dagogique.\n",
    "    \"\"\"\n",
    "\n",
    "    return analyze_with_mistral(prompt)\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR INTERAGIR AVEC MISTRAL AI ----\n",
    "def analyze_with_mistral(prompt):\n",
    "    \"\"\"Envoie un prompt √† Mistral AI via Amazon Bedrock.\"\"\"\n",
    "    request_body = {\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"temperature\": 0.3, \n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=MODEL_ID,\n",
    "        body=json.dumps(request_body)\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response[\"body\"].read())\n",
    "    return response_body.get(\"outputs\", [{}])[0].get(\"text\", \"\")\n",
    "\n",
    "\n",
    "# ---- EX√âCUTION ----\n",
    "if __name__ == \"__main__\":\n",
    "    response = agent_analyze_tables()\n",
    "    print(\"\\nüìä Analyse des Tables Redshift üìä\\n\")\n",
    "    print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
