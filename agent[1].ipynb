{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for boto3 from https://files.pythonhosted.org/packages/4e/a5/e6f90b0a768560a0c44cb9076a313ee6d669ec98fd2747a8451832403ffe/boto3-1.36.11-py3-none-any.whl.metadata\n",
      "  Downloading boto3-1.36.11-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/e9/65/e5cc2876078fa5f1a621c8429f0174855c7e9831060d350626dbf8d2a10c/langchain-0.3.17-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.3.17-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting psycopg2-binary\n",
      "  Obtaining dependency information for psycopg2-binary from https://files.pythonhosted.org/packages/61/69/3b3d7bd583c6d3cbe5100802efa5beacaacc86e37b653fc708bf3d6853b8/psycopg2_binary-2.9.10-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading psycopg2_binary-2.9.10-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\zinii\\appdata\\roaming\\python\\python311\\site-packages (2.2.3)\n",
      "Collecting faiss-cpu\n",
      "  Obtaining dependency information for faiss-cpu from https://files.pythonhosted.org/packages/2c/2d/d2a4171a9cca9a7c04cd9d6f9441a37f1e0558724b90bf7fc7db08553601/faiss_cpu-1.10.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading faiss_cpu-1.10.0-cp311-cp311-win_amd64.whl.metadata (4.5 kB)\n",
      "Collecting botocore<1.37.0,>=1.36.11 (from boto3)\n",
      "  Obtaining dependency information for botocore<1.37.0,>=1.36.11 from https://files.pythonhosted.org/packages/2c/ce/e97be00389d51a010c0680ea688a073737ca3b2de6f924800fc61bf68e41/botocore-1.36.11-py3-none-any.whl.metadata\n",
      "  Downloading botocore-1.36.11-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from boto3) (0.10.0)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3)\n",
      "  Obtaining dependency information for s3transfer<0.12.0,>=0.11.0 from https://files.pythonhosted.org/packages/1b/ac/e7dc469e49048dc57f62e0c555d2ee3117fa30813d2a1a2962cce3a2a82a/s3transfer-0.11.2-py3-none-any.whl.metadata\n",
      "  Downloading s3transfer-0.11.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Collecting langchain-core<0.4.0,>=0.3.33 (from langchain)\n",
      "  Obtaining dependency information for langchain-core<0.4.0,>=0.3.33 from https://files.pythonhosted.org/packages/98/78/463bc92174555cc04b3e234faa169bb8b58f36fff77892d7b8ae2b4f58e4/langchain_core-0.3.33-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.3.33-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Obtaining dependency information for langchain-text-splitters<0.4.0,>=0.3.3 from https://files.pythonhosted.org/packages/4b/83/f8081c3bea416bd9d9f0c26af795c74f42c24f9ad3c4fbf361b7d69de134/langchain_text_splitters-0.3.5-py3-none-any.whl.metadata\n",
      "  Downloading langchain_text_splitters-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.4,>=0.1.17 from https://files.pythonhosted.org/packages/47/3b/02313e378f6328ada43ee43ecc81a398b4f68e207c94770d1ed6aac6cca2/langsmith-0.3.4-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.3.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Obtaining dependency information for pydantic<3.0.0,>=2.7.4 from https://files.pythonhosted.org/packages/f4/3c/8cc1cc84deffa6e25d2d0c688ebb80635dfdbf1dbea3e30c541c8cf4d860/pydantic-2.10.6-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\zinii\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\zinii\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\zinii\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2025.1)\n",
      "Collecting numpy<2,>=1.22.4 (from langchain)\n",
      "  Obtaining dependency information for numpy<2,>=1.22.4 from https://files.pythonhosted.org/packages/3f/6b/5610004206cf7f8e7ad91c5a85a8c71b2f2f8051a0c0c4d5916b76d6cbb2/numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.0/61.0 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from faiss-cpu) (23.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from botocore<1.37.0,>=1.36.11->boto3) (1.26.16)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.33->langchain)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging (from faiss-cpu)\n",
      "  Obtaining dependency information for packaging from https://files.pythonhosted.org/packages/88/ef/eb23f262cca3c0c4eb7ab1933c3b1f03d021f2c48f54763065b6f0e321be/packaging-24.2-py3-none-any.whl.metadata\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\zinii\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (4.12.2)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/2a/39/e50c7c3a983047577ee07d2a9e53faf5a69493943ec3f6a384bdc792deb2/httpx-0.28.1-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Obtaining dependency information for orjson<4.0.0,>=3.9.14 from https://files.pythonhosted.org/packages/00/f8/bb60a4644287a544ec81df1699d5b965776bc9848d9029d9f9b3402ac8bb/orjson-3.10.15-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading orjson-3.10.15-cp311-cp311-win_amd64.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.9/42.9 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Obtaining dependency information for zstandard<0.24.0,>=0.23.0 from https://files.pythonhosted.org/packages/be/a2/4272175d47c623ff78196f3c10e9dc7045c1b9caf3735bf041e65271eca4/zstandard-0.23.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading zstandard-0.23.0-cp311-cp311-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Obtaining dependency information for annotated-types>=0.6.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Obtaining dependency information for pydantic-core==2.27.2 from https://files.pythonhosted.org/packages/e8/ef/013f07248041b74abd48a385e2110aa3a9bbfef0fbd97d4e6d07d2f5b89a/pydantic_core-2.27.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zinii\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.5.0)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/87/f5/72347bc88306acb359581ac4d52f23c0ef445b57157adedb9aee0cd689d2/httpcore-1.0.7-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Obtaining dependency information for h11<0.15,>=0.13 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain) (2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.0)\n",
      "Using cached boto3-1.36.11-py3-none-any.whl (139 kB)\n",
      "Using cached langchain-0.3.17-py3-none-any.whl (1.0 MB)\n",
      "Using cached psycopg2_binary-2.9.10-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "Using cached faiss_cpu-1.10.0-cp311-cp311-win_amd64.whl (13.7 MB)\n",
      "Using cached botocore-1.36.11-py3-none-any.whl (13.3 MB)\n",
      "Using cached langchain_core-0.3.33-py3-none-any.whl (412 kB)\n",
      "Using cached langchain_text_splitters-0.3.5-py3-none-any.whl (31 kB)\n",
      "Using cached langsmith-0.3.4-py3-none-any.whl (333 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "Using cached s3transfer-0.11.2-py3-none-any.whl (84 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached orjson-3.10.15-cp311-cp311-win_amd64.whl (133 kB)\n",
      "Using cached zstandard-0.23.0-cp311-cp311-win_amd64.whl (495 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: zstandard, pydantic-core, psycopg2-binary, packaging, orjson, numpy, jsonpatch, h11, annotated-types, pydantic, httpcore, faiss-cpu, botocore, s3transfer, httpx, langsmith, boto3, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: zstandard\n",
      "    Found existing installation: zstandard 0.19.0\n",
      "    Uninstalling zstandard-0.19.0:\n",
      "      Successfully uninstalled zstandard-0.19.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.8\n",
      "    Uninstalling pydantic-1.10.8:\n",
      "      Successfully uninstalled pydantic-1.10.8\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.76\n",
      "    Uninstalling botocore-1.29.76:\n",
      "      Successfully uninstalled botocore-1.29.76\n",
      "Successfully installed annotated-types-0.7.0 boto3-1.36.11 botocore-1.36.11 faiss-cpu-1.10.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jsonpatch-1.33 langchain-0.3.17 langchain-core-0.3.33 langchain-text-splitters-0.3.5 langsmith-0.3.4 numpy-1.26.4 orjson-3.10.15 packaging-24.2 psycopg2-binary-2.9.10 pydantic-2.10.6 pydantic-core-2.27.2 s3transfer-0.11.2 zstandard-0.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "aiobotocore 2.5.0 requires botocore<1.29.77,>=1.29.76, but you have botocore 1.36.11 which is incompatible.\n",
      "anaconda-cloud-auth 0.1.3 requires pydantic<2.0, but you have pydantic 2.10.6 which is incompatible.\n",
      "numba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\n",
      "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2024.12.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install boto3 langchain psycopg2-binary pandas faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session(region_name='us-west-2')\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# Option 1: Use default credential provider chain\n",
    "session = boto3.Session()\n",
    "\n",
    "print(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2: Use specific profile\n",
    "session = boto3.Session(profile_name='default')\n",
    "\n",
    "# Option 3: Use environment variables\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'your_access_key'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'your_secret_key'\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'your-region-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All available models in my region: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID: amazon.titan-tg1-large\n",
      "Model ID: amazon.titan-embed-g1-text-02\n",
      "Model ID: amazon.titan-text-lite-v1:0:4k\n",
      "Model ID: amazon.titan-text-lite-v1\n",
      "Model ID: amazon.titan-text-express-v1:0:8k\n",
      "Model ID: amazon.titan-text-express-v1\n",
      "Model ID: amazon.nova-pro-v1:0\n",
      "Model ID: amazon.nova-lite-v1:0\n",
      "Model ID: amazon.nova-micro-v1:0\n",
      "Model ID: amazon.titan-embed-text-v1:2:8k\n",
      "Model ID: amazon.titan-embed-text-v1\n",
      "Model ID: amazon.titan-embed-text-v2:0\n",
      "Model ID: amazon.titan-embed-image-v1:0\n",
      "Model ID: amazon.titan-embed-image-v1\n",
      "Model ID: amazon.titan-image-generator-v1:0\n",
      "Model ID: amazon.titan-image-generator-v1\n",
      "Model ID: amazon.titan-image-generator-v2:0\n",
      "Model ID: amazon.rerank-v1:0\n",
      "Model ID: stability.stable-diffusion-xl-v1:0\n",
      "Model ID: stability.stable-diffusion-xl-v1\n",
      "Model ID: stability.sd3-large-v1:0\n",
      "Model ID: stability.sd3-5-large-v1:0\n",
      "Model ID: stability.stable-image-core-v1:0\n",
      "Model ID: stability.stable-image-core-v1:1\n",
      "Model ID: stability.stable-image-ultra-v1:0\n",
      "Model ID: stability.stable-image-ultra-v1:1\n",
      "Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0:18k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0:51k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0:200k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0\n",
      "Model ID: anthropic.claude-3-5-haiku-20241022-v1:0\n",
      "Model ID: anthropic.claude-instant-v1:2:100k\n",
      "Model ID: anthropic.claude-instant-v1\n",
      "Model ID: anthropic.claude-v2:0:18k\n",
      "Model ID: anthropic.claude-v2:0:100k\n",
      "Model ID: anthropic.claude-v2:1:18k\n",
      "Model ID: anthropic.claude-v2:1:200k\n",
      "Model ID: anthropic.claude-v2:1\n",
      "Model ID: anthropic.claude-v2\n",
      "Model ID: anthropic.claude-3-sonnet-20240229-v1:0:28k\n",
      "Model ID: anthropic.claude-3-sonnet-20240229-v1:0:200k\n",
      "Model ID: anthropic.claude-3-sonnet-20240229-v1:0\n",
      "Model ID: anthropic.claude-3-haiku-20240307-v1:0:48k\n",
      "Model ID: anthropic.claude-3-haiku-20240307-v1:0:200k\n",
      "Model ID: anthropic.claude-3-haiku-20240307-v1:0\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0:12k\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0:28k\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0:200k\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0\n",
      "Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0:18k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0:51k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0:200k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0\n",
      "Model ID: cohere.command-text-v14:7:4k\n",
      "Model ID: cohere.command-text-v14\n",
      "Model ID: cohere.command-r-v1:0\n",
      "Model ID: cohere.command-r-plus-v1:0\n",
      "Model ID: cohere.command-light-text-v14:7:4k\n",
      "Model ID: cohere.command-light-text-v14\n",
      "Model ID: cohere.embed-english-v3:0:512\n",
      "Model ID: cohere.embed-english-v3\n",
      "Model ID: cohere.embed-multilingual-v3:0:512\n",
      "Model ID: cohere.embed-multilingual-v3\n",
      "Model ID: cohere.rerank-v3-5:0\n",
      "Model ID: meta.llama3-8b-instruct-v1:0\n",
      "Model ID: meta.llama3-70b-instruct-v1:0\n",
      "Model ID: meta.llama3-1-8b-instruct-v1:0:128k\n",
      "Model ID: meta.llama3-1-8b-instruct-v1:0\n",
      "Model ID: meta.llama3-1-70b-instruct-v1:0:128k\n",
      "Model ID: meta.llama3-1-70b-instruct-v1:0\n",
      "Model ID: meta.llama3-1-405b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-11b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-90b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-1b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-3b-instruct-v1:0\n",
      "Model ID: meta.llama3-3-70b-instruct-v1:0\n",
      "Model ID: mistral.mistral-7b-instruct-v0:2\n",
      "Model ID: mistral.mixtral-8x7b-instruct-v0:1\n",
      "Model ID: mistral.mistral-large-2402-v1:0\n",
      "Model ID: mistral.mistral-large-2407-v1:0\n",
      "Model ID: luma.ray-v2:0\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "bedrock = boto3.client('bedrock', region_name='us-west-2')  # change to your region\n",
    "models = bedrock.list_foundation_models()\n",
    "\n",
    "for model in models['modelSummaries']:\n",
    "    print(f\"Model ID: {model['modelId']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: What are three interesting facts about the Pacific Northwest?\n",
      "\n",
      "Titan's response: \n",
      "Here are three interesting facts about the Pacific Northwest: \n",
      "\n",
      "1. \"The Pacific Northwest is one of the most beautiful places in the United States. Located along the coast of the Pacific Ocean, it includes Washington, Oregon, and Idaho. The region is known for its stunning scenery, including mountains, forests, and waterways. Here are three interesting facts about the Pacific Northwest:\n",
      "2. The Cascade Range is one of the most prominent mountain ranges in the Pacific Northwest. It includes several volcanoes, including Mount St. Helens and Mount Rainier, and offers some of the best skiing and hiking in the United States.\n",
      "3. The region is also home to several indigenous tribes, including the Nez Perce, Flathead, and Salish. These tribes have a rich history and culture and continue to play an important role in the Pacific Northwest today.\" \n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "def simple_titan_agent(prompt: str) -> str:\n",
    "    # Initialize Bedrock Runtime client in us-west-2\n",
    "    bedrock = boto3.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        region_name='us-west-2'\n",
    "    )\n",
    "    \n",
    "    # Prepare the request for Titan\n",
    "    request_body = {\n",
    "        \"inputText\": prompt,\n",
    "        \"textGenerationConfig\": {\n",
    "            \"maxTokenCount\": 100,\n",
    "            \"temperature\": 0,\n",
    "            \"topP\": 1,\n",
    "            \"stopSequences\": []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Use Titan Express model\n",
    "    model_id = 'amazon.titan-text-express-v1'\n",
    "    \n",
    "    # Invoke the model\n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body=json.dumps(request_body)\n",
    "    )\n",
    "    \n",
    "    # Parse and return the response\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    return response_body.get('results', [{}])[0].get('outputText', '')\n",
    "\n",
    "# Test the agent\n",
    "if __name__ == \"__main__\":\n",
    "    test_prompt = \"What are three interesting facts about the Pacific Northwest?\"\n",
    "    \n",
    "    try:\n",
    "        response = simple_titan_agent(test_prompt)\n",
    "        print(\"\\nPrompt:\", test_prompt)\n",
    "        print(\"\\nTitan's response:\", response)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreatedAt': datetime.datetime(2025, 2, 1, 21, 38, 14, 565000, tzinfo=tzlocal()), 'Database': 'dev', 'DbUser': 'IAM:child-account-21-user-1', 'Id': '970d035b-afe0-49ce-af60-d965dad6b91a', 'WorkgroupName': 'wz-solutions-redshift-workgroup', 'ResponseMetadata': {'RequestId': '970d035b-afe0-49ce-af60-d965dad6b91a', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '970d035b-afe0-49ce-af60-d965dad6b91a', 'content-type': 'application/x-amz-json-1.1', 'content-length': '180', 'date': 'Sat, 01 Feb 2025 20:38:14 GMT'}, 'RetryAttempts': 0}}\n",
      "Connexion réussie !\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialisation du client Redshift Data\n",
    "client = boto3.client('redshift-data', region_name='us-west-2')\n",
    "\n",
    "# Paramètres de connexion\n",
    "database = 'dev'  # Remplace par le nom de ta base de données\n",
    "workgroup_name = 'wz-solutions-redshift-workgroup'  # Remplace par ton workgroup\n",
    "\n",
    "# Requête simple pour tester la connexion\n",
    "sql_query = 'SELECT 1;'\n",
    "\n",
    "try:\n",
    "    response = client.execute_statement(\n",
    "        Database=database,\n",
    "        WorkgroupName=workgroup_name,  # Ne spécifie plus db_user ici\n",
    "        Sql=sql_query\n",
    "    )\n",
    "    print(\"Connexion réussie !\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur de connexion : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requête envoyée, ID : 979c0d74-e9e9-427c-97ce-50786006a8a5\n",
      "En attente des résultats...\n",
      "\n",
      "Résultats de la requête :\n",
      "['GN_1180180102051605', 'GN|1180180102051605|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180102342604', 'GN|1180180102342604|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180102501103', 'GN|1180180102501103|22910|1|00000', '2022-10-10', 'NULL', '2022-03-27', '2022-09-02', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180102596604', 'GN|1180180102596604|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180102978210', 'GN|1180180102978210|22910|1|00000', '2022-10-10', 'NULL', '2022-03-27', '2022-09-02', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180103044102', 'GN|1180180103044102|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180103080601', 'GN|1180180103080601|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180103081401', 'GN|1180180103081401|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180103156901', 'GN|1180180103156901|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n",
      "['GN_1180180103398201', 'GN|1180180103398201|22910|1|00000', '2022-10-10', 'NULL', '2022-03-28', '2022-09-03', 'NULL', 'NULL', 'NULL']\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "# Initialisation du client Redshift Data\n",
    "client = boto3.client('redshift-data', region_name='us-west-2')\n",
    "\n",
    "# Paramètres de connexion\n",
    "database = 'dev'  # Remplace par le nom de ta base de données\n",
    "workgroup_name = 'wz-solutions-redshift-workgroup'  # Remplace par ton workgroup\n",
    "\n",
    "# Requête SQL à exécuter\n",
    "sql_query = 'SELECT * FROM consoma LIMIT 10;'  # Remplace par ta table\n",
    "\n",
    "try:\n",
    "    # Exécuter la requête SQL\n",
    "    response = client.execute_statement(\n",
    "        Database=database,\n",
    "        WorkgroupName=workgroup_name,  # Ne spécifie plus db_user ici\n",
    "        Sql=sql_query\n",
    "    )\n",
    "    \n",
    "    # Récupérer l'ID de l'exécution de la requête\n",
    "    statement_id = response['Id']\n",
    "    print(f\"Requête envoyée, ID : {statement_id}\")\n",
    "\n",
    "    # Attendre que la requête soit terminée\n",
    "    while True:\n",
    "        status_response = client.describe_statement(Id=statement_id)\n",
    "        status = status_response['Status']\n",
    "\n",
    "        if status in ['FINISHED', 'FAILED', 'ABORTED']:\n",
    "            break\n",
    "        print(\"En attente des résultats...\")\n",
    "        time.sleep(2)  # Pause avant la prochaine vérification\n",
    "\n",
    "    # Vérifier si la requête s'est bien exécutée\n",
    "    if status == 'FINISHED':\n",
    "        # Récupérer les résultats\n",
    "        result_response = client.get_statement_result(Id=statement_id)\n",
    "        records = result_response.get('Records', [])\n",
    "\n",
    "        # Afficher les résultats\n",
    "        if records:\n",
    "            print(\"\\nRésultats de la requête :\")\n",
    "            for row in records:\n",
    "                print([col.get('stringValue', 'NULL') for col in row])  # Adaptation pour afficher chaque ligne\n",
    "        else:\n",
    "            print(\"Aucun résultat trouvé.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Erreur lors de l'exécution : {status_response.get('Error', 'Erreur inconnue')}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erreur de connexion ou d'exécution : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requête envoyée, ID : 7267a7c4-ae12-4479-9a26-6323221fe820\n",
      "En attente des résultats...\n",
      "\n",
      "📊 Rapport de Qualité des Données 📊\n",
      "\n",
      "\n",
      "Anomalies détectées :\n",
      "- Des dates de début de contrat manquantes.\n",
      "- Des dates de fin de contrat manquantes.\n",
      "- Des dates de début de contrat antérieures à la date de fin de contrat.\n",
      "\n",
      "Requête SQL de validation :\n",
      "SELECT *\n",
      "FROM abonnements\n",
      "WHERE date_de_fin_contrat < date_de_debut_contrat;\n",
      "\n",
      "Recommandations d'amélioration :\n",
      "- Vérifier et corriger les dates de début et de fin de contrat manquantes.\n",
      "- Vérifier la cohérence des dates de début et de fin de contrat.\n",
      "- Enrichir la table avec des informations complémentaires sur les contrats.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "\n",
    "# ---- AWS CONFIGURATION ----\n",
    "AWS_REGION = \"us-west-2\"\n",
    "MODEL_ID = \"amazon.titan-text-express-v1\"\n",
    "\n",
    "# ---- REDSHIFT SERVERLESS CONFIGURATION ----\n",
    "DATABASE = \"dev\"  # Remplace par ta base de données\n",
    "WORKGROUP_NAME = \"wz-solutions-redshift-workgroup\"  # Remplace par ton workgroup\n",
    "\n",
    "# ---- INITIALISATION DES CLIENTS ----\n",
    "bedrock = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\n",
    "redshift_client = boto3.client(\"redshift-data\", region_name=AWS_REGION)\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR INTERROGER REDSHIFT ----\n",
    "def query_redshift(sql_query):\n",
    "    \"\"\"Exécute une requête SQL sur Redshift Serverless et retourne les résultats.\"\"\"\n",
    "    try:\n",
    "        response = redshift_client.execute_statement(\n",
    "            Database=DATABASE,\n",
    "            WorkgroupName=WORKGROUP_NAME,\n",
    "            Sql=sql_query\n",
    "        )\n",
    "\n",
    "        statement_id = response['Id']\n",
    "        print(f\"Requête envoyée, ID : {statement_id}\")\n",
    "\n",
    "        while True:\n",
    "            status_response = redshift_client.describe_statement(Id=statement_id)\n",
    "            status = status_response[\"Status\"]\n",
    "\n",
    "            if status in [\"FINISHED\", \"FAILED\", \"ABORTED\"]:\n",
    "                break\n",
    "            print(\"En attente des résultats...\")\n",
    "            time.sleep(2)\n",
    "\n",
    "        if status == \"FINISHED\":\n",
    "            result_response = redshift_client.get_statement_result(Id=statement_id)\n",
    "            records = result_response.get(\"Records\", [])\n",
    "            return records if records else \"Aucun résultat trouvé.\"\n",
    "        else:\n",
    "            return f\"Erreur lors de l'exécution : {status_response.get('Error', 'Erreur inconnue')}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Erreur de connexion ou d'exécution : {str(e)}\"\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR ANALYSER LES DONNÉES AVEC AMAZON TITAN ----\n",
    "def analyze_data_with_titan(prompt):\n",
    "    \"\"\"Envoie un prompt structuré à Amazon Titan pour détecter les anomalies et proposer des actions correctives.\"\"\"\n",
    "    request_body = {\n",
    "        \"inputText\": prompt,\n",
    "        \"textGenerationConfig\": {\n",
    "            \"maxTokenCount\": 300,\n",
    "            \"temperature\": 0,\n",
    "            \"topP\": 1,\n",
    "            \"stopSequences\": []\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=MODEL_ID,\n",
    "        body=json.dumps(request_body)\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response[\"body\"].read())\n",
    "    return response_body.get(\"results\", [{}])[0].get(\"outputText\", \"\")\n",
    "\n",
    "\n",
    "# ---- FONCTION PRINCIPALE : ANALYSE DE QUALITÉ DES DONNÉES ----\n",
    "def data_quality_analysis(table_name):\n",
    "    \"\"\"Analyse la qualité des données d'une table Redshift et détecte des anomalies.\"\"\"\n",
    "    sql_query = f\"SELECT * FROM {table_name} LIMIT 10;\"\n",
    "    records = query_redshift(sql_query)\n",
    "\n",
    "    if isinstance(records, str):\n",
    "        return records\n",
    "\n",
    "    formatted_data = \"\\n\".join([\", \".join([col.get('stringValue', 'NULL') for col in row]) for row in records])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Tu es un expert en qualité des données, spécialisé dans l'analyse de tables Redshift.\n",
    "    \n",
    "    Voici un échantillon de la table \"{table_name}\":\n",
    "    {formatted_data}\n",
    "    \n",
    "    1. Identifie les anomalies ou incohérences dans ces données.\n",
    "    2. Génère une requête SQL pour approfondir l'analyse.\n",
    "    3. Suggère des bonnes pratiques pour améliorer la qualité des données.\n",
    "\n",
    "    Format attendu :\n",
    "    - Anomalies détectées\n",
    "    - Requête SQL de validation\n",
    "    - Recommandations d'amélioration\n",
    "    \"\"\"\n",
    "\n",
    "    return analyze_data_with_titan(prompt)\n",
    "\n",
    "\n",
    "# ---- EXÉCUTION ----\n",
    "if __name__ == \"__main__\":\n",
    "    table_name = \"abonnements\"  # Remplace par le nom de ta table Redshift\n",
    "    response = data_quality_analysis(table_name)\n",
    "\n",
    "    print(\"\\n📊 Rapport de Qualité des Données 📊\\n\")\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROSPER: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Analyse des Tables Redshift 📊\n",
      "\n",
      "\n",
      "    Table: abonnements\n",
      "\n",
      "    1. Le rôle de cette table dans la base de données est de stocker les informations relatives aux abonnements des clients. Cela inclut des détails tels que le numéro d'abonnement, les dates d'entrée, de résiliation et de souscription.\n",
      "\n",
      "    2. Les colonnes de cette table sont :\n",
      "\n",
      "    - cle_abonnement (character varying) : Cette colonne stocke le numéro d'abonnement unique pour chaque client.\n",
      "    \n",
      "    - date_entree_local_abonnement (date) : Cette colonne enregistre la date à laquelle l'abonnement a été souscrit par le client.\n",
      "    \n",
      "    - date_resiliation_abonnement (date) : Cette colonne stocke la date à laquelle l'abonnement a été résilié par le client. Si l'abonnement est toujours actif, cette valeur sera NULL.\n",
      "    \n",
      "    - date_souscription_abonnement (date) : Cette colonne enregistre la date à laquelle l'abonnement a été souscrit par le client. Cette valeur devrait être identique à celle stockée dans la colonne date_entree_local_abonnement.\n",
      "\n",
      "    Table: consommations\n",
      "\n",
      "    1. Le rôle de cette table dans la base de données est de stocker les informations sur la consommation d'eau pour chaque client. Cela inclut des détails tels que le volume consommé, le diamètre nominal de la conduite, le type d'abaque utilisé pour le calcul de la consommation, ainsi que des informations sur la catégorie de l'abonné, le contrat, le territoire et la région.\n",
      "\n",
      "    2. Les colonnes de cette table sont :\n",
      "\n",
      "    - annee_conso (integer) : Cette colonne stocke l'année de consommation.\n",
      "    \n",
      "    - mois_conso (integer) : Cette colonne enregistre le mois de consommation.\n",
      "    \n",
      "    - diametre_nominal (real) : Cette colonne stocke le diamètre nominal de la conduite d'eau pour le client.\n",
      "    \n",
      "    - volume_mois (double precision) : Cette colonne enregistre le volume d'eau consommé par le client pendant le mois spécifié.\n",
      "    \n",
      "    - type_abaque (character varying) : Cette colonne stocke le type d'abaque utilisé pour calculer la consommation d'eau pour le client.\n",
      "    \n",
      "    - libelle_categorie_abonne (character varying) : Cette colonne enregistre la catégorie de l'abonné (par exemple, résidentiel, commercial, industriel).\n",
      "    \n",
      "    - code_contrat (character varying) : Cette colonne stocke le code de contrat associé à l'abonnement du client.\n",
      "    \n",
      "    - libelle_territoire (character varying) : Cette colonne enregistre le nom du territoire où se trouve l'abonnement du client.\n",
      "    \n",
      "    - libelle_region (character varying) : Cette colonne stocke le nom de la région où se trouve l'abonnement du client.\n",
      "    \n",
      "    - cle_pds (character varying) : Cette colonne stocke un identifiant unique pour chaque point de livraison (PDL).\n",
      "    \n",
      "    - date_conso_mois (date) : Cette colonne enregistre la date à laquelle la consommation a été mesurée.\n",
      "\n",
      "    Table: factures\n",
      "\n",
      "    1. Le rôle de cette table dans la base de données est de stocker les informations sur les factures émises pour chaque abonnement. Cela inclut des détails tels que le numéro de facture, le nombre de jours facturés, le nombre de factures par point de livraison, la consommation facturée et les dates d'émission, de relevé d'index et de relevé d'index précédent.\n",
      "\n",
      "    2. Les colonnes de cette table sont :\n",
      "\n",
      "    - num_fac_par_pds (integer) : Cette colonne stocke le numéro de facture par point de livraison.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "\n",
    "# ---- AWS CONFIGURATION ----\n",
    "AWS_REGION = \"us-west-2\"\n",
    "MODEL_ID = \"mistral.mixtral-8x7b-instruct-v0:1\"  # Utilisation de Mistral AI\n",
    "\n",
    "# ---- REDSHIFT SERVERLESS CONFIGURATION ----\n",
    "DATABASE = \"dev\"  # Remplace par ta base de données\n",
    "WORKGROUP_NAME = \"wz-solutions-redshift-workgroup\"  # Remplace par ton workgroup\n",
    "\n",
    "# ---- INITIALISATION DES CLIENTS ----\n",
    "bedrock = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\n",
    "redshift_client = boto3.client(\"redshift-data\", region_name=AWS_REGION)\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR RÉCUPÉRER LES TABLES REDSHIFT ----\n",
    "def get_redshift_tables():\n",
    "    \"\"\"Récupère la liste des tables disponibles dans la base de données Redshift.\"\"\"\n",
    "    sql_query = \"SELECT tablename FROM pg_catalog.pg_tables WHERE schemaname = 'public';\"\n",
    "    try:\n",
    "        response = redshift_client.execute_statement(\n",
    "            Database=DATABASE,\n",
    "            WorkgroupName=WORKGROUP_NAME,\n",
    "            Sql=sql_query\n",
    "        )\n",
    "\n",
    "        statement_id = response['Id']\n",
    "        while True:\n",
    "            status_response = redshift_client.describe_statement(Id=statement_id)\n",
    "            status = status_response[\"Status\"]\n",
    "            if status in [\"FINISHED\", \"FAILED\", \"ABORTED\"]:\n",
    "                break\n",
    "            time.sleep(2)\n",
    "\n",
    "        if status == \"FINISHED\":\n",
    "            result_response = redshift_client.get_statement_result(Id=statement_id)\n",
    "            tables = [row[0].get('stringValue', 'NULL') for row in result_response.get(\"Records\", [])]\n",
    "            return tables if tables else \"Aucune table trouvée.\"\n",
    "        else:\n",
    "            return f\"Erreur lors de l'exécution : {status_response.get('Error', 'Erreur inconnue')}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Erreur de connexion ou d'exécution : {str(e)}\"\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR RÉCUPÉRER LES COLONNES D'UNE TABLE ----\n",
    "def get_table_columns(table_name):\n",
    "    \"\"\"Récupère les colonnes et leur description d'une table Redshift.\"\"\"\n",
    "    sql_query = f\"\"\"\n",
    "        SELECT column_name, data_type\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_name = '{table_name}';\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = redshift_client.execute_statement(\n",
    "            Database=DATABASE,\n",
    "            WorkgroupName=WORKGROUP_NAME,\n",
    "            Sql=sql_query\n",
    "        )\n",
    "\n",
    "        statement_id = response['Id']\n",
    "        while True:\n",
    "            status_response = redshift_client.describe_statement(Id=statement_id)\n",
    "            status = status_response[\"Status\"]\n",
    "            if status in [\"FINISHED\", \"FAILED\", \"ABORTED\"]:\n",
    "                break\n",
    "            time.sleep(2)\n",
    "\n",
    "        if status == \"FINISHED\":\n",
    "            result_response = redshift_client.get_statement_result(Id=statement_id)\n",
    "            columns = [\n",
    "                f\"{row[0].get('stringValue', 'NULL')} ({row[1].get('stringValue', 'NULL')})\"\n",
    "                for row in result_response.get(\"Records\", [])\n",
    "            ]\n",
    "            return columns if columns else \"Aucune colonne trouvée.\"\n",
    "        else:\n",
    "            return f\"Erreur lors de l'exécution : {status_response.get('Error', 'Erreur inconnue')}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Erreur de connexion ou d'exécution : {str(e)}\"\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR ANALYSER LES TABLES AVEC L'AGENT ----\n",
    "def agent_analyze_tables():\n",
    "    \"\"\"Analyse et décrit chaque table détectée dans Redshift.\"\"\"\n",
    "    tables = get_redshift_tables()\n",
    "    if isinstance(tables, str):\n",
    "        return tables\n",
    "\n",
    "    all_tables_info = []\n",
    "    for table in tables:\n",
    "        columns = get_table_columns(table)\n",
    "        all_tables_info.append(f\"Table: {table}\\nColonnes: {', '.join(columns)}\")\n",
    "\n",
    "    # Construire le prompt pour Mistral AI\n",
    "    prompt = f\"\"\"\n",
    "    Tu es un expert en bases de données. Analyse et décris chacune des tables trouvées dans Amazon Redshift.\n",
    "    \n",
    "    Voici les informations trouvées :\n",
    "    {chr(10).join(all_tables_info)}\n",
    "\n",
    "    Pour chaque table :\n",
    "    1. Donne son rôle dans la base de données.\n",
    "    2. Explique à quoi sert chaque colonne.\n",
    "    \n",
    "    Réponds de manière détaillée et pédagogique.\n",
    "    \"\"\"\n",
    "\n",
    "    return analyze_with_mistral(prompt)\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR INTERAGIR AVEC MISTRAL AI ----\n",
    "def analyze_with_mistral(prompt):\n",
    "    \"\"\"Envoie un prompt à Mistral AI via Amazon Bedrock.\"\"\"\n",
    "    request_body = {\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"temperature\": 0.3, \n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=MODEL_ID,\n",
    "        body=json.dumps(request_body)\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response[\"body\"].read())\n",
    "    return response_body.get(\"outputs\", [{}])[0].get(\"text\", \"\")\n",
    "\n",
    "\n",
    "# ---- EXÉCUTION ----\n",
    "if __name__ == \"__main__\":\n",
    "    response = agent_analyze_tables()\n",
    "    print(\"\\n📊 Analyse des Tables Redshift 📊\\n\")\n",
    "    print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
