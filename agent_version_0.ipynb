{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **ATTENTION**: ce fichier montre notre avancement sur ce que nous avons fait concernant la cr√©ation de notre agent MAIS n'est pas utilis√© dans le code final !!\n",
        "\n",
        "En effet, nous avons abandonn√© cette piste pour la cr√©ation de notre agent et nous l'avons fait d'une mani√®re diff√©rente: veuillez voir le fichier agent.ipynb\n",
        "\n",
        "Pour plus de d√©tail sur cette approche et pourquoi nous l'avons abandonn√©, veuillez vous r√©f√©rer √† la partie \"Nos difficult√©s\" pr√©sent dans le README.md. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDgMe_xKASCq"
      },
      "source": [
        "2Ô∏è‚É£ Se connecter √† AWS avec Boto3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2OPloviAOo6",
        "outputId": "1fc2ad24-fb07-4449-ed4f-198c456517c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Connexion √† AWS r√©ussie !\n"
          ]
        }
      ],
      "source": [
        "import boto3\n",
        "\n",
        "# üîë Remplace par tes cl√©s d‚Äôacc√®s (depuis ton fichier .csv AWS)\n",
        "aws_access_key_id = \"AKIA3FRRJFPLAUZDQ65K\"\n",
        "aws_secret_access_key = \"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\"\n",
        "\n",
        "# üóÑÔ∏è Nom du bucket S3 o√π stocker les fichiers\n",
        "BUCKET_NAME = \"veolia-data-quality\"\n",
        "\n",
        "# üîÑ Initialiser le client S3\n",
        "s3_client = boto3.client(\n",
        "    \"s3\",\n",
        "    aws_access_key_id=aws_access_key_id,\n",
        "    aws_secret_access_key=aws_secret_access_key,\n",
        "    region_name=\"us-west-2\"  # Remplace si besoin\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Connexion √† AWS r√©ussie !\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGQiMoEHAT7v"
      },
      "source": [
        "üìå √âtape 2 : Uploader un fichier CSV depuis Colab vers S3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "EXrBxONsAVvm",
        "outputId": "69a0a1d9-b6e5-40c5-a415-f944ccb88793"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1046c013-011b-4ee1-bae8-b631a00bce7a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1046c013-011b-4ee1-bae8-b631a00bce7a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving veolia-data-abonnements.csv to veolia-data-abonnements.csv\n",
            "Saving veolia-data-consos.csv to veolia-data-consos.csv\n",
            "Saving veolia-data-factures.csv to veolia-data-factures.csv\n",
            "‚úÖ veolia-data-abonnements.csv a √©t√© upload√© sur S3 dans veolia-data-quality/\n",
            "‚úÖ veolia-data-consos.csv a √©t√© upload√© sur S3 dans veolia-data-quality/\n",
            "‚úÖ veolia-data-factures.csv a √©t√© upload√© sur S3 dans veolia-data-quality/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# üìÇ S√©lectionner les fichiers CSV √† uploader\n",
        "uploaded = files.upload()\n",
        "\n",
        "# üì§ Uploader chaque fichier CSV sur S3\n",
        "for filename in uploaded.keys():\n",
        "    s3_client.upload_file(filename, BUCKET_NAME, filename)\n",
        "    print(f\"‚úÖ {filename} a √©t√© upload√© sur S3 dans {BUCKET_NAME}/\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOjhCzfmAZUt"
      },
      "source": [
        "üìå √âtape 3 : Charger un fichier CSV depuis S3 vers Pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0Wewh36AW3R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "# üîπ Nom du fichier √† r√©cup√©rer (remplace par le bon nom)\n",
        "FILENAME = \"veolia-data-abonnements.csv\"\n",
        "\n",
        "# T√©l√©charger le fichier depuis S3\n",
        "csv_obj = s3_client.get_object(Bucket=BUCKET_NAME, Key=FILENAME)\n",
        "csv_data = csv_obj[\"Body\"].read().decode(\"utf-8\")\n",
        "\n",
        "# Charger dans Pandas\n",
        "df = pd.read_csv(StringIO(csv_data))\n",
        "print(\"‚úÖ Fichier charg√© depuis S3 avec succ√®s !\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UoCBq0_ERii"
      },
      "source": [
        "üìå √âtape 3 : V√©rifier que les fichiers sont bien sur S3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXn5Z_QFEQQ1",
        "outputId": "3b0a395c-cc85-4353-e904-763a998c29e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Fichier trouv√© : veolia-data-abonnements.csv\n",
            "üìÇ Fichier trouv√© : veolia-data-consos.csv\n",
            "üìÇ Fichier trouv√© : veolia-data-factures.csv\n"
          ]
        }
      ],
      "source": [
        "response = s3_client.list_objects_v2(Bucket=BUCKET_NAME)\n",
        "for obj in response.get(\"Contents\", []):\n",
        "    print(\"üìÇ Fichier trouv√© :\", obj[\"Key\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGFWCuZrEUl3"
      },
      "source": [
        "üìå √âtape 4 : Charger les fichiers CSV depuis S3 pour analyse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ8CwyAOEQfN",
        "outputId": "5a82e8b6-c4a0-474f-a666-26e64ea05e59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Donn√©es charg√©es depuis S3 avec succ√®s !\n",
            "        CLE_ABONNEMENT DATE_ENTREE_LOCAL_ABONNEMENT  \\\n",
            "0  GN_1180180100000501                          NaN   \n",
            "1  GN_1180180100000506                   2014-11-19   \n",
            "2  GN_1180180100000901                          NaN   \n",
            "3  GN_1180180100004301                          NaN   \n",
            "4  GN_1180180100012507                   2004-11-19   \n",
            "\n",
            "  DATE_SOUSCRIPTION_ABONNEMENT DATE_RESILIATION_ABONNEMENT  \n",
            "0                          NaN                  2003-09-16  \n",
            "1                   2014-11-25                  2015-09-10  \n",
            "2                          NaN                  2003-02-21  \n",
            "3                          NaN                  1993-12-16  \n",
            "4                   2004-11-19                  2007-01-01  \n",
            "             CLE_PDS LIBELLE_REGION LIBELLE_TERRITOIRE CODE_CONTRAT  \\\n",
            "0  GN|07744010200392  Ile de France     Seine et Marne        E4660   \n",
            "1  GN|07744010201832  Ile de France     Seine et Marne        E4660   \n",
            "2  GN|07421002002279  Ile de France     Seine et Marne        E4660   \n",
            "3  GN|07421002002647  Ile de France     Seine et Marne        E4660   \n",
            "4  GN|07421001002741  Ile de France     Seine et Marne        E4660   \n",
            "\n",
            "       LIBELLE_CATEGORIE_ABONNE  DIAMETRE_NOMINAL        TYPE_ABAQUE  \\\n",
            "0                PROFESSIONNELS               0.0            INACTIF   \n",
            "1                PROFESSIONNELS              15.0            INACTIF   \n",
            "2                PROFESSIONNELS              15.0            INACTIF   \n",
            "3   APPAREILS PUBLICS COMMUNAUX              20.0  ABAQUE_ML_INTERPO   \n",
            "4  BATIMENTS COLLECTIFS PUBLICS              40.0  ABAQUE_ML_INTERPO   \n",
            "\n",
            "   MOIS_CONSO  ANNEE_CONSO DATE_CONSO_MOIS  VOLUME_MOIS  \n",
            "0           8         2022      2022-08-01     0.000000  \n",
            "1           8         2022      2022-08-01     0.000000  \n",
            "2           8         2022      2022-08-01     0.000000  \n",
            "3           1         2024      2024-01-01     0.000000  \n",
            "4           1         2024      2024-01-01    48.454092  \n",
            "        CLE_ABONNEMENT                        CLE_FACTURE  \\\n",
            "0  GN_0782301010021705  GN|0782301010021705|23563|1|00000   \n",
            "1  GN_0742100100201901  GN|0742100100201901|24513|1|00000   \n",
            "2  GN_0742100100202001  GN|0742100100202001|23320|1|00000   \n",
            "3  GN_0742100100202001  GN|0742100100202001|24320|1|00000   \n",
            "4  GN_0742100100202604  GN|0742100100202604|24320|1|00000   \n",
            "\n",
            "  DATE_EMISSION_FACTURE  CONSO_FACTURE  \\\n",
            "0            2023-12-21            156   \n",
            "1            2024-03-29          38199   \n",
            "2            2023-05-03            359   \n",
            "3            2024-04-24            290   \n",
            "4            2024-04-24             89   \n",
            "\n",
            "  DATE_RELEVE_INDEX_PRECEDENT_FACTURE_COMPOSITE DATE_RELEVE_INDEX_FACTURE  \\\n",
            "0                                    2023-11-29                2023-11-30   \n",
            "1                                    2023-04-13                2024-03-13   \n",
            "2                                    2022-04-05                2023-04-03   \n",
            "3                                    2023-04-03                2024-04-09   \n",
            "4                                    2023-04-04                2024-03-21   \n",
            "\n",
            "   NB_FACTURES_PAR_PDS  NB_JOURS_CONNUS  NUM_FAC_PAR_PDS  \n",
            "0                    6                1                4  \n",
            "1                    1              335                1  \n",
            "2                    2              363                1  \n",
            "3                    2              372                2  \n",
            "4                    1              352                1  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "# Fonction pour charger un CSV depuis S3\n",
        "def load_csv_from_s3(filename):\n",
        "    obj = s3_client.get_object(Bucket=BUCKET_NAME, Key=filename)\n",
        "    return pd.read_csv(StringIO(obj[\"Body\"].read().decode(\"utf-8\")))\n",
        "\n",
        "# Charger les fichiers depuis S3\n",
        "df_abonnements = load_csv_from_s3(\"veolia-data-abonnements.csv\")\n",
        "df_consommation = load_csv_from_s3(\"veolia-data-consos.csv\")\n",
        "df_factures = load_csv_from_s3(\"veolia-data-factures.csv\")\n",
        "\n",
        "print(\"‚úÖ Donn√©es charg√©es depuis S3 avec succ√®s !\")\n",
        "print(df_abonnements.head())\n",
        "print(df_consommation.head())\n",
        "print(df_factures.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aj2WhmC4EWSL",
        "outputId": "9fbf20cd-4e8e-4613-da7a-09a2be04aef6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç Valeurs manquantes (%) par colonne :\n",
            "\n",
            "üìÇ ABONNEMENTS:\n",
            "CLE_ABONNEMENT                   0.000000\n",
            "DATE_ENTREE_LOCAL_ABONNEMENT    19.052854\n",
            "DATE_SOUSCRIPTION_ABONNEMENT    36.761099\n",
            "DATE_RESILIATION_ABONNEMENT     49.547569\n",
            "dtype: float64\n",
            "\n",
            "üìÇ CONSOMMATION:\n",
            "CLE_PDS                     0.000000\n",
            "LIBELLE_REGION              0.000000\n",
            "LIBELLE_TERRITOIRE          0.000000\n",
            "CODE_CONTRAT                0.000000\n",
            "LIBELLE_CATEGORIE_ABONNE    0.000000\n",
            "DIAMETRE_NOMINAL            0.307964\n",
            "TYPE_ABAQUE                 0.000000\n",
            "MOIS_CONSO                  0.000000\n",
            "ANNEE_CONSO                 0.000000\n",
            "DATE_CONSO_MOIS             0.000000\n",
            "VOLUME_MOIS                 0.000000\n",
            "dtype: float64\n",
            "\n",
            "üìÇ FACTURES:\n",
            "CLE_ABONNEMENT                                   0.0\n",
            "CLE_FACTURE                                      0.0\n",
            "DATE_EMISSION_FACTURE                            0.0\n",
            "CONSO_FACTURE                                    0.0\n",
            "DATE_RELEVE_INDEX_PRECEDENT_FACTURE_COMPOSITE    0.0\n",
            "DATE_RELEVE_INDEX_FACTURE                        0.0\n",
            "NB_FACTURES_PAR_PDS                              0.0\n",
            "NB_JOURS_CONNUS                                  0.0\n",
            "NUM_FAC_PAR_PDS                                  0.0\n",
            "dtype: float64\n",
            "\n",
            "‚ùå Anomalies r√©siliation avant souscription : 6\n",
            "\n",
            "‚ùå Anomalies abonnements tr√®s anciens : 47\n",
            "\n",
            "‚ùå Consommations aberrantes : 1\n",
            "\n",
            "üîç Top 10 des √©carts consommation vs facturation :\n",
            "Empty DataFrame\n",
            "Columns: [VOLUME_MOIS, CONSO_FACTURE, Ecart]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "# üóìÔ∏è Convertir les colonnes de date\n",
        "for col in ['DATE_ENTREE_LOCAL_ABONNEMENT', 'DATE_SOUSCRIPTION_ABONNEMENT', 'DATE_RESILIATION_ABONNEMENT']:\n",
        "    df_abonnements[col] = pd.to_datetime(df_abonnements[col], errors='coerce')\n",
        "\n",
        "df_consommation['DATE_CONSO_MOIS'] = pd.to_datetime(df_consommation['DATE_CONSO_MOIS'], errors='coerce')\n",
        "\n",
        "for col in ['DATE_EMISSION_FACTURE', 'DATE_RELEVE_INDEX_PRECEDENT_FACTURE_COMPOSITE', 'DATE_RELEVE_INDEX_FACTURE']:\n",
        "    df_factures[col] = pd.to_datetime(df_factures[col], errors='coerce')\n",
        "\n",
        "# üìâ Valeurs manquantes\n",
        "missing_values = {\n",
        "    \"abonnements\": df_abonnements.isna().mean() * 100,\n",
        "    \"consommation\": df_consommation.isna().mean() * 100,\n",
        "    \"factures\": df_factures.isna().mean() * 100,\n",
        "}\n",
        "\n",
        "print(\"\\nüîç Valeurs manquantes (%) par colonne :\")\n",
        "for key, value in missing_values.items():\n",
        "    print(f\"\\nüìÇ {key.upper()}:\")\n",
        "    print(value)\n",
        "\n",
        "# ‚ùå Anomalies sur les abonnements\n",
        "anomalies_resiliation = df_abonnements[df_abonnements['DATE_RESILIATION_ABONNEMENT'] < df_abonnements['DATE_SOUSCRIPTION_ABONNEMENT']]\n",
        "print(f\"\\n‚ùå Anomalies r√©siliation avant souscription : {len(anomalies_resiliation)}\")\n",
        "\n",
        "anomalies_anciennes = df_abonnements[\n",
        "    (df_abonnements['DATE_ENTREE_LOCAL_ABONNEMENT'].dt.year < 1990) &\n",
        "    df_abonnements['DATE_SOUSCRIPTION_ABONNEMENT'].isna() &\n",
        "    df_abonnements['DATE_RESILIATION_ABONNEMENT'].isna()\n",
        "]\n",
        "print(f\"\\n‚ùå Anomalies abonnements tr√®s anciens : {len(anomalies_anciennes)}\")\n",
        "\n",
        "# ‚ùå Anomalies sur les consommations\n",
        "conso_aberrante = df_consommation[(df_consommation['VOLUME_MOIS'] < 0) | (df_consommation['VOLUME_MOIS'] > 100000)]\n",
        "print(f\"\\n‚ùå Consommations aberrantes : {len(conso_aberrante)}\")\n",
        "\n",
        "# üìä Comparaison consommation vs facturation\n",
        "conso_mensuelle_par_abonne = df_consommation.groupby('CLE_PDS')['VOLUME_MOIS'].sum()\n",
        "facture_par_abonne = df_factures.groupby('CLE_ABONNEMENT')['CONSO_FACTURE'].sum()\n",
        "\n",
        "comparaison = conso_mensuelle_par_abonne.to_frame().merge(facture_par_abonne.to_frame(), left_index=True, right_index=True, how='inner')\n",
        "comparaison['Ecart'] = abs(comparaison['VOLUME_MOIS'] - comparaison['CONSO_FACTURE'])\n",
        "\n",
        "print(\"\\nüîç Top 10 des √©carts consommation vs facturation :\")\n",
        "print(comparaison.sort_values(by='Ecart', ascending=False).head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg102s3uEcUG",
        "outputId": "82b5852d-304b-4480-fa15-a12e4f190740"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ R√©sultats enregistr√©s sur S3 : results/quality_check.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# üìå Structurer les r√©sultats\n",
        "results = {\n",
        "    \"missing_values\": {k: v.to_dict() for k, v in missing_values.items()},\n",
        "    \"anomalies_resiliation\": len(anomalies_resiliation),\n",
        "    \"anomalies_anciennes\": len(anomalies_anciennes),\n",
        "    \"conso_aberrante\": len(conso_aberrante),\n",
        "    \"top_ecarts_facturation\": comparaison.sort_values(by='Ecart', ascending=False).head(10).to_dict()\n",
        "}\n",
        "\n",
        "# üì§ Convertir en JSON et envoyer sur S3\n",
        "json_data = json.dumps(results)\n",
        "s3_client.put_object(Bucket=BUCKET_NAME, Key=\"results/quality_check.json\", Body=json_data)\n",
        "\n",
        "print(\"‚úÖ R√©sultats enregistr√©s sur S3 : results/quality_check.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWqy-TW7Egtq",
        "outputId": "c023476e-34bc-4d4d-eedc-86c8a53d0759"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ R√©sultats d'analyse r√©cup√©r√©s depuis S3 !\n",
            "{\n",
            "  \"missing_values\": {\n",
            "    \"abonnements\": {\n",
            "      \"CLE_ABONNEMENT\": 0.0,\n",
            "      \"DATE_ENTREE_LOCAL_ABONNEMENT\": 19.052854122621564,\n",
            "      \"DATE_SOUSCRIPTION_ABONNEMENT\": 36.761099365750525,\n",
            "      \"DATE_RESILIATION_ABONNEMENT\": 49.54756871035941\n",
            "    },\n",
            "    \"consommation\": {\n",
            "      \"CLE_PDS\": 0.0,\n",
            "      \"LIBELLE_REGION\": 0.0,\n",
            "      \"LIBELLE_TERRITOIRE\": 0.0,\n",
            "      \"CODE_CONTRAT\": 0.0,\n",
            "      \"LIBELLE_CATEGORIE_ABONNE\": 0.0,\n",
            "      \"DIAMETRE_NOMINAL\": 0.3079644725043314,\n",
            "      \"TYPE_ABAQUE\": 0.0,\n",
            "      \"MOIS_CONSO\": 0.0,\n",
            "      \"ANNEE_CONSO\": 0.0,\n",
            "      \"DATE_CONSO_MOIS\": 0.0,\n",
            "      \"VOLUME_MOIS\": 0.0\n",
            "    },\n",
            "    \"factures\": {\n",
            "      \"CLE_ABONNEMENT\": 0.0,\n",
            "      \"CLE_FACTURE\": 0.0,\n",
            "      \"DATE_EMISSION_FACTURE\": 0.0,\n",
            "      \"CONSO_FACTURE\": 0.0,\n",
            "      \"DATE_RELEVE_INDEX_PRECEDENT_FACTURE_COMPOSITE\": 0.0,\n",
            "      \"DATE_RELEVE_INDEX_FACTURE\": 0.0,\n",
            "      \"NB_FACTURES_PAR_PDS\": 0.0,\n",
            "      \"NB_JOURS_CONNUS\": 0.0,\n",
            "      \"NUM_FAC_PAR_PDS\": 0.0\n",
            "    }\n",
            "  },\n",
            "  \"anomalies_resiliation\": 6,\n",
            "  \"anomalies_anciennes\": 47,\n",
            "  \"conso_aberrante\": 1,\n",
            "  \"top_ecarts_facturation\": {\n",
            "    \"VOLUME_MOIS\": {},\n",
            "    \"CONSO_FACTURE\": {},\n",
            "    \"Ecart\": {}\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from io import StringIO\n",
        "\n",
        "# üì• T√©l√©charger le JSON d'analyse depuis S3\n",
        "def load_json_from_s3(filename):\n",
        "    obj = s3_client.get_object(Bucket=BUCKET_NAME, Key=filename)\n",
        "    return json.loads(obj[\"Body\"].read().decode(\"utf-8\"))\n",
        "\n",
        "# Charger les r√©sultats stock√©s sur S3\n",
        "results = load_json_from_s3(\"results/quality_check.json\")\n",
        "\n",
        "print(\"‚úÖ R√©sultats d'analyse r√©cup√©r√©s depuis S3 !\")\n",
        "print(json.dumps(results, indent=2))  # Afficher les r√©sultats de fa√ßon lisible\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGqyzsSJFoqy",
        "outputId": "0588dbec-82ef-4f3e-ead1-3cfb182c5c98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ R√©ponse de l'IA :\n",
            "{\n",
            "  \"outputs\": [\n",
            "    {\n",
            "      \"text\": \"\\ud83d\\udcdd **R\\u00e9ponses attendues** :\\n\\n    ```json\\n    {\\n      \\\"anomalies_detected\\\": [\\n        \\\"Pr\\u00e9sence de valeurs manquantes dans les colonnes CLE_ABONNEMENT, DATE_ENTREE_LOCAL_ABONNEMENT, DATE_SOUSCRIPTION_ABONNEMENT et DATE_RESILIATION_ABONNEMENT des abonnements.\\\",\\n        \\\"Existence de factures avec des volumes de consommation aberrants par rapport \\u00e0 l\\u2019historique de consommation.\\\"\\n      ],\\n      \\\"sql_queries\\\": [\\n        \\\"SELECT CLE_ABONNEMENT, COUNT(*) FROM abonnements WHERE CLE_ABONNEMENT IS NULL GROUP BY CLE_ABONNEMENT HAVING COUNT(*) > 0;\\\",\\n        \\\"SELECT CLE_ABONNEMENT FROM abonnements WHERE DATE_ENTREE_LOCAL_ABONNEMENT IS NULL;\\\",\\n        \\\"SELECT CLE_ABONNEMENT FROM abonnements WHERE DATE_SOUSCRIPTION_ABONNEMENT IS NULL;\\\",\\n        \\\"SELECT CLE_ABONNEMENT FROM abonnements WHERE DATE_RESILIATION_ABONNEMENT IS NULL;\\\",\\n        \\\"SELECT CLE_PDS, COUNT(*) FROM consommation WHERE VOLUME_MOIS > 1000000 GROUP BY CLE_PDS HAVING COUNT(*) > 0;\\\",\\n        \\\"SELECT CLE_ABONNEMENT FROM factures WHERE CONSO_FACTURE > 2 * (SELECT AVG(CONSO_FACTURE) FROM factures WHERE CLE_ABONNEMENT = f.CLE_ABONNEMENT) GROUP BY CLE_ABONNEMENT;\\\"\\n      ],\\n      \\\"suggested_controls\\\": [\\n        \\\"Ajouter une contrainte NOT NULL sur les colonnes CLE_ABONNEMENT, DATE_ENTREE_LOCAL_ABONNEMENT, DATE_SOUSCRIPTION_ABONNEMENT et DATE_RESILIATION_ABONNEMENT de la table abonnements.\\\",\\n        \\\"Mettre en place un contr\\u00f4le de coh\\u00e9rence sur les volumes de consommation en comparant les valeurs actuelles avec l\\u2019historique de consommation.\\\",\\n        \\\"V\\u00e9rifier la coh\\u00e9rence des factures par rapport \\u00e0 l\\u2019historique de consommation avant validation.\\\"\\n      ]\\n    }\\n    ```\",\n",
            "      \"stop_reason\": \"stop\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import boto3\n",
        "import json\n",
        "\n",
        "# üîÑ Initialiser AWS Bedrock\n",
        "bedrock_client = boto3.client(\n",
        "    \"bedrock-runtime\",\n",
        "    region_name=\"us-west-2\",  # Change si ta r√©gion est diff√©rente\n",
        "    aws_access_key_id=aws_access_key_id,\n",
        "    aws_secret_access_key=aws_secret_access_key\n",
        ")\n",
        "\n",
        "# üìå Construire le prompt pour l‚ÄôIA\n",
        "def generate_prompt(results):\n",
        "    return f\"\"\"\n",
        "    üéØ **R√¥le** :\n",
        "    Tu es un expert en qualit√© des donn√©es. Ton objectif est de d√©tecter les anomalies et de g√©n√©rer des requ√™tes SQL pour am√©liorer la qualit√© des donn√©es dans Redshift.\n",
        "\n",
        "    üìÇ **Donn√©es fournies** :\n",
        "    - Nous travaillons avec des donn√©es de consommation et de facturation d‚Äôeau.\n",
        "    - Chaque abonnement est li√© √† une consommation mensuelle et une facturation correspondante.\n",
        "    - Certaines valeurs peuvent √™tre incoh√©rentes ou erron√©es.\n",
        "\n",
        "    üìä **Analyse des donn√©es** :\n",
        "    Voici un r√©sum√© des probl√®mes d√©tect√©s :\n",
        "    {json.dumps(results, indent=2)}\n",
        "\n",
        "    üîç **Ta mission** :\n",
        "    1Ô∏è‚É£ D√©crire en une phrase les anomalies les plus critiques et leur impact.\n",
        "    2Ô∏è‚É£ G√©n√©rer des requ√™tes SQL Redshift optimis√©es pour d√©tecter ou corriger ces anomalies.\n",
        "    3Ô∏è‚É£ Proposer des contr√¥les suppl√©mentaires pour √©viter ces erreurs dans le futur.\n",
        "\n",
        "    ‚ö†Ô∏è **Format attendu (JSON uniquement, sans texte superflu)** :\n",
        "    ```json\n",
        "    {{\n",
        "      \"anomalies_detected\": [\"Valeur manquante dans DATE_ENTREE_LOCAL_ABONNEMENT\", \"Facture incoh√©rente avec consommation\"],\n",
        "      \"sql_queries\": [\n",
        "        \"SELECT * FROM abonnements WHERE DATE_ENTREE_LOCAL_ABONNEMENT IS NULL\",\n",
        "        \"SELECT CLE_ABONNEMENT FROM factures WHERE CONSO_FACTURE > 2 * (SELECT AVG(CONSO_FACTURE) FROM factures)\"\n",
        "      ],\n",
        "      \"suggested_controls\": [\n",
        "        \"Mettre en place une contrainte NOT NULL sur DATE_ENTREE_LOCAL_ABONNEMENT\",\n",
        "        \"V√©rifier les √©carts de facturation de plus de 2x la moyenne avant validation\"\n",
        "      ]\n",
        "    }}\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "# üì° Envoyer le prompt au mod√®le `Mixtral 8x7B Instruct`\n",
        "def analyze_data_with_ai(results):\n",
        "    response = bedrock_client.invoke_model(\n",
        "        modelId=\"mistral.mixtral-8x7b-instruct-v0:1\",  # ‚úÖ ID du mod√®le mis √† jour !\n",
        "        contentType=\"application/json\",\n",
        "        accept=\"application/json\",\n",
        "        body=json.dumps({\"prompt\": generate_prompt(results), \"max_tokens\": 800})\n",
        "    )\n",
        "    return json.loads(response[\"body\"].read())\n",
        "\n",
        "# üî• Ex√©cuter l‚Äôanalyse avec `Mixtral 8x7B Instruct`\n",
        "ai_response = analyze_data_with_ai(results)\n",
        "print(\"‚úÖ R√©ponse de l'IA :\")\n",
        "print(json.dumps(ai_response, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hjJsNKIFumA",
        "outputId": "7598d977-cd8b-4dfe-8a36-a6b4dc8a6e26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Anomalies d√©tect√©es : ['Pr√©sence de valeurs manquantes dans les colonnes CLE_ABONNEMENT, DATE_ENTREE_LOCAL_ABONNEMENT, DATE_SOUSCRIPTION_ABONNEMENT et DATE_RESILIATION_ABONNEMENT des abonnements.', 'Existence de factures avec des volumes de consommation aberrants par rapport √† l‚Äôhistorique de consommation.']\n",
            "‚úÖ Requ√™tes SQL g√©n√©r√©es : ['SELECT CLE_ABONNEMENT, COUNT(*) FROM abonnements WHERE CLE_ABONNEMENT IS NULL GROUP BY CLE_ABONNEMENT HAVING COUNT(*) > 0;', 'SELECT CLE_ABONNEMENT FROM abonnements WHERE DATE_ENTREE_LOCAL_ABONNEMENT IS NULL;', 'SELECT CLE_ABONNEMENT FROM abonnements WHERE DATE_SOUSCRIPTION_ABONNEMENT IS NULL;', 'SELECT CLE_ABONNEMENT FROM abonnements WHERE DATE_RESILIATION_ABONNEMENT IS NULL;', 'SELECT CLE_PDS, COUNT(*) FROM consommation WHERE VOLUME_MOIS > 1000000 GROUP BY CLE_PDS HAVING COUNT(*) > 0;', 'SELECT CLE_ABONNEMENT FROM factures WHERE CONSO_FACTURE > 2 * (SELECT AVG(CONSO_FACTURE) FROM factures WHERE CLE_ABONNEMENT = f.CLE_ABONNEMENT) GROUP BY CLE_ABONNEMENT;']\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "def extract_json(ai_response):\n",
        "    text = ai_response[\"outputs\"][0][\"text\"]\n",
        "\n",
        "    # üîç Extraire tout ce qui est entre ```json et ```\n",
        "    matches = re.findall(r'```json\\s*(\\{.*?\\})\\s*```', text, re.DOTALL)\n",
        "\n",
        "    for match in matches:\n",
        "        try:\n",
        "            return json.loads(match)  # Essaye de charger le premier JSON valide\n",
        "        except json.JSONDecodeError:\n",
        "            continue  # Si erreur, continue avec le suivant\n",
        "\n",
        "    print(\"‚ùå Aucun JSON valide trouv√© dans la r√©ponse IA\")\n",
        "    print(\"üîç R√©ponse brute de l'IA :\", text[:500])  # Afficher les 500 premiers caract√®res pour diagnostic\n",
        "    return {}\n",
        "\n",
        "# üîç Nettoyer la r√©ponse IA et r√©cup√©rer uniquement le JSON utile\n",
        "cleaned_response = extract_json(ai_response)\n",
        "\n",
        "# üìå Afficher les anomalies et requ√™tes SQL extraites\n",
        "print(\"‚úÖ Anomalies d√©tect√©es :\", cleaned_response.get(\"anomalies_detected\", []))\n",
        "print(\"‚úÖ Requ√™tes SQL g√©n√©r√©es :\", cleaned_response.get(\"sql_queries\", []))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQat_L5_HAtJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
